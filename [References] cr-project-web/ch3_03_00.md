# **6. 기술 적용 방식** 
### **개요**
-----
기사 품질을 평가하는 AI 시스템을 어떻게 만들 것인지에 대한 전략을 설명합니다. 다소 복잡한 기술적 내용이지만, 핵심은 '단계적 접근'입니다. 처음부터 완벽한 시스템을 구축하기보다, 작은 것부터 시작해 점진적으로 발전시키는 전략을 채택했습니다. 

초기에는 이미 상용화된 AI 서비스(Claude, GPT, Gemini 등)를 활용해 빠르게 시작하고, 중기에는 적은 데이터로도 효과적인 '파인튜닝' 방식을 적용하며, 장기적으로 한국 언론 텍스트에 완전히 최적화된 자체 AI 모델을 개발하는 계획입니다. 이런 단계적 접근은 제한된 자원으로도 프로젝트를 시작할 수 있게 하면서, 장기적으로 더 정교하고 독립적인 시스템을 구축할 수 있게 합니다. 

특히 오픈소스 AI 모델을 활용한 접근법은 CR 프로젝트의 '시민 주도', '독립성', '지속가능성'이라는 핵심 가치와도 잘 맞아떨어집니다. 초기 개발 비용은 다소 높겠지만, 장기적으로는 더 경제적이고 자율성이 높은 방식이 될 것입니다. 

# **6-1. AI 모델 전략 및 의사결정** 
## **6-1-1. AI 모델 선택 및 개발 전략** 
현실적인 리소스 제약과 점진적 발전을 고려한 단계적 AI 개발 전략을 수립: 

- **초기 단계: 프롬프트 엔지니어링 접근법** 
  - GPT-4나 Claude와 같은 상용 API 활용 → 빠른 프로토타이핑과 [MVP](https://brunch.co.kr/@dongdong1/14) 출시 
  - 프롬프트 엔지니어링으로 한국어 언론 텍스트 특성 반영 
  - 사용자 피드백 수집 및 방향성 검증 
- **중기 단계: LoRA 기반 경량 파인튜닝** 
  - [LoRA](https://bcho.tistory.com/1452)[(Low-Rank Adaptation)](https://bcho.tistory.com/1452) 방식을 활용한 효율적 모델 개발 
  - 적은 데이터(500~1,000개, 최신 LLM의 강력한 인컨텍스트 학습 능력과 프롬프트 엔지니어링 발전으로 실제로는 잘 정리된 50~100개 정도의 예시만 있어도 충분히 좋은 결과를 얻을 수 있으며, 특히 CR 프로젝트처럼 명확한 평가 기준이 있는 작업은 몇 개의 예시만 보여주거나(Few-shot) 심지어 예시 없이 설명만으로도(Zero-shot) 꽤 정확한 평가가 가능해짐)와 컴퓨팅 자원으로도 효과적인 특화 모델 개발 
  - 1개 GPU(NVIDIA T4/V100) 환경에서 2~4시간 내외 학습 가능 
  - 원본 모델 대비 추가 2~10MB의 어댑터 파일만 생성되는 경량 솔루션 
- **장기 단계: 맞춤형 AI 모델 개발** 
  - 충분한 데이터 확보 후 [KoBERT](https://github.com/SKTBrain/KoBERT), [KoGPT](https://github.com/kakaobrain/kogpt) 등 한국어 특화 모델 파인튜닝 
  - 언론 텍스트 코퍼스에 최적화된 자체 모델 구축 
  - 다양한 기사 유형과 주제에 특화된 모델 앙상블 개발 

자체 개발 모델의 장점은 한국 언론의 특수성에 최적화, 장기적 비용 효율성, 독립성과 통제력 보장이며, 이는 CR 프로젝트의 핵심 가치와 일치한다. 
## **6-1-2. LLM 접근 방식 비교 분석** 
현실적인 리소스 제약과 점진적 발전을 고려한 단계적 AI 개발 전략을 수립: 
### **대중적 AI 서비스 API 활용 방식**
- **모델 옵션** : OpenAI GPT-4, Anthropic Claude, Google Gemini 
- **장점** : 
  - 빠른 구축 및 배포 가능 
  - 최신 모델 성능 즉시 활용 가능 
  - 인프라 관리 부담 최소화 
  - 초기 개발 비용 절감 
  - 안정적인 서비스 품질 보장 
- **단점** : 
  - API 호출 비용 지속 발생 (규모 확장 시 비용 급증) 
  - 데이터 프라이버시 우려 (외부 서비스에 데이터 전송) 
  - 커스터마이징 제한적 
  - 외부 서비스 의존성으로 인한 리스크 
  - 특화된 저널리즘 평가 능력 제한적 
### **오픈소스 LLM 파인튜닝 방식**
- **모델 옵션** : Llama 4(최대 256K 토큰 컨텍스트 윈도우를 지원), DeepSeek R1-0528(671B 파라미터, MoE 아키텍처, 토큰당 37B 활성), Qwen 3(235B-A22B), Gemma3(27B), HyperCLOVA X(204B+ 파라미터, Naver), EXAONE 3.5(2.4B, 7.8B, 32B, LG AI Research), Mixtral(22B), Pixtral(12B, Mixtral AI의 멀티모달로 확장한 모델)
- **장점** : 
  - 저널리즘 평가에 특화된 모델 개발 가능 
  - 장기적 비용 효율성 (초기 투자 후 운영 비용 감소) 
  - 데이터 프라이버시 보장 
  - 완전한 커스터마이징 가능 
  - 독자적 기술력 확보 
- **단점** : 
  - 초기 개발 및 학습 비용 높음 
  - 전문 인력 필요 (ML 엔지니어, 데이터 과학자) 
  - 인프라 구축 및 관리 부담 
  - 개발 및 최적화에 시간 소요 
  - 모델 업데이트 및 유지보수 책임 
## **6-1-3. CR 프로젝트에 적합한 접근법** 
CR 프로젝트의 목표와 특성을 고려할 때, **오픈소스 LLM 파인튜닝 방식** 이 더 적합: 
### **프로젝트 철학과의 일치성** 
CR 프로젝트는 "시민 주도", "기성 언론에 대한 독립적 평가"를 강조. 오픈소스 접근법은 "접근성, 개방성, 확장성"이라는 핵심 원칙과 일치하며, "비영리를 철저히 고수"한다는 원칙에 부합하는 지속 가능한 모델이다. 
### **맞춤형 평가 역량** 
다차원 매트릭스 평가는 고도로 특화된 작업으로, 파인튜닝을 통해 한국 언론 맥락(무주체 피동형 문장, 익명 취재원 관행 등)에 최적화할 수 있음. 
### **데이터 자주권과 프라이버시** 
자체 호스팅 모델은 분석 데이터가 외부 서비스로 전송되지 않아 프라이버시를 보장할 수 있음. 상업적 API의 정책 변경이나 서비스 중단 위험에서도 자유롭다. 
### **비용 효율성과 지속가능성** 
초기 구축 비용은 높지만, 사용량이 증가할수록 API 방식보다 경제적입니다. 시민 참여형 프로젝트로서 지속가능한 운영 모델 구축에 적합하다. 
### **커뮤니티 참여와 확장성** 
오픈소스 접근방식은 기술 커뮤니티의 참여와 기여를 유도합니다. 다양한 형태의 미디어 비평 플랫폼으로 확장하는 "하나의 네트워크"를 구축하는 데 유리하다. 

# **6-2. 시스템 아키텍처 설계** 
## **6-2-1. 계층적 모델 아키텍처 설계** 
5단계 분류를 기반으로 다음 그림과 같은 AI 시스템 구조를 제안함: 

Input Layer -> Text Processing -> \
{ \
취재원 분석 모듈, \
사실 검증 모듈, \
표현 방식 평가 모듈, \
상업성 감지 모듈, \
구조적 문제 탐지 모듈 \
} \
-> 종합 품질 점수 

각 모듈은 해당 범주의 하위 지표들을 가중치 조합으로 평가한다. 예를 들어 표현 방식 평가 모듈은 피동형 표현 빈도(가중치 0.3), 단정적 용어 사용(0.4), 감정적 수식어 빈도(0.3) 등을 종합함. 
## **6-2-2. 마이크로서비스 기반 시스템 아키텍처** 
확장성과 유연성을 극대화하기 위해 '마이크로서비스 기반 모듈형 아키텍처'를 적용. 이 구조는 크게 세 층위로 나뉜다: 
### **코어 서비스 레이어**
API 게이트웨이를 중심으로 기사 추출 서비스, 품질 평가 엔진, 사용자 관리, 데이터 저장소 등 독립적인 마이크로서비스로 구성한다. 각 서비스는 독자적으로 확장 가능하며, 한 서비스의 장애가 전체 시스템에 영향을 미치지 않는다. 
### **플러그인 레이어**
새로운 평가 알고리즘, 데이터 시각화 모듈, 언어 지원 등을 플러그인 형태로 개발할 수 있게 한다. 코어 시스템 수정 없이도 기능을 확장할 수 있으며, Open API 명세를 공개하여 외부 개발자 생태계를 조성함. 
### **프론트엔드 레이어**
React와 같은 컴포넌트 기반 프레임워크로 구현하여 UI 요소의 재사용성과 확장성을 높일 수 있다. 

시스템 간 통신은 이벤트 기반 아키텍처를 적용하여 비동기 처리를 구현하고, 특정 서비스의 병목 현상을 방지. 또한 서버리스 컴퓨팅을 활용하여 초기 비용을 절감하고 트래픽에 따른 자동 확장이 가능하도록 설계한다. 
## **6-2-3. 추가적인 고려 사항** 
- **데이터셋 구축** : 각 문제 유형별로 최소 300개 이상의 기사 샘플을 확보(LLM 성능 향상 확인 후 퓨샷 맥시멈 재설정)하고, 자발적 참여 인력을 통해 정확하게 레이블링한다. 
- **가중치 설정** : 언론 윤리 전문가, 시민단체, 학계 등 다양한 이해관계자의 의견을 수렴하여 객관적이고 공정한 가중치를 설정한다. 
- **모델 검증** : 구축된 데이터셋을 활용하여 AI 모델의 성능을 검증하고, 지속적인 개선을 통해 정확도를 높인다. 

# **6-3. 성능 최적화 및 패턴 인식 기술** 
## **6-3-1. AI 모델 배포 및 성능 최적화 전략** 
사용자에게 빠른 응답 시간을 제공하면서도 분석 정확도를 유지하기 위해 다음과 같은 모델 배포 전략을 적용한다: 
### **계층적 모델 파이프라인**
전체 분석 과정을 3단계로 구분하여 처리한다. 

- 1단계(필터링): 경량화된 모델(DistilKoBERT 등)로 기본적인 패턴 탐지와 기사 유형 분류. 
- 2단계(중간 분석): 일반적인 품질 평가 수행. 
- 3단계(심층 분석): 복잡한 패턴이나 상세 분석이 필요한 경우에만 대형 모델 활용. 
### **모델 최적화 기법**
- 모델 양자화: 32비트 모델을 8비트 정수형으로 변환하여 크기 축소. 
- 모델 프루닝: 중요도가 낮은 가중치 제거로 모델 크기 70%까지 축소하면서 성능 저하는 3% 미만 유지. 
- 모델 증류: 대형 모델의 지식을 경량 모델로 전달하는 지식 증류 기법 적용. 
### **하이브리드 클라우드-엣지 접근법**
- 경량 모델은 사용자 기기에서 직접 실행하여 응답 지연 최소화. 
- 복잡한 분석은 클라우드에서 처리하되, GPU 가속 활용. 
- 지리적 분산 배치로 네트워크 지연 최소화. 
### **지능형 캐싱 전략**
- 자주 분석되는 기사 결과를 Redis 기반 캐싱 시스템에 저장. 
- 유사 기사에 대한 부분 결과 재활용으로 계산 효율성 향상. 
## **6-3-2. 계층적 패턴 인식 시스템** 
기사 텍스트의 문제적 패턴을 효과적으로 식별하기 위해 계층적 패턴 인식 시스템을 도입. 이 접근법은 자원 집약적인 과거 데이터 분석 없이도 현재 기사의 품질을 정확하게 평가할 수 있다: 

문제적 표현 탐지 → 문맥 평가 → 품질 영향 분석. 

이 시스템은 다음 세 가지 계층으로 구성된다: 
### **기본 패턴 인식 계층**
무주체 피동형 표현, 익명 취재원, 주관적 술어 등 문제적 표현을 정규표현식과 구문 분석을 통해 1차적으로 식별함. 
### **문맥 이해 계층**
패턴이 사용된 문맥을 분석하여 예외적으로 허용 가능한 경우(예: 북한 관련 보도에서의 익명 취재원)와 문제가 되는 경우를 구분한다. 이는 단순 패턴 매칭의 한계를 보완. 
### **영향도 평가 계층**
식별된 패턴이 8개 핵심 평가 차원(진실성, 투명성 등)에 미치는 영향을 계산한다. 동일 패턴이라도 반복 사용 시 로그함수적 감점을 적용하고, 패턴 결합(예: 익명+피동형)에는 추가 감점을 부여한다. 

이 계층적 시스템은 기사 유형과 길이에 따라 유연하게 가중치를 조정하며, 수학적으로는 다음과 같이 표현할 수 있다: 

S\_d = b\_d - Σ(w\_i,d × f(p\_i)) 

여기서 S\_d는 차원 d의 점수, b\_d는 기본 점수, w\_i,d는 패턴 i가 차원 d에 미치는 영향 가중치, f(p\_i)는 패턴 i의 발생 빈도에 대한 로그함수적 감점 함수. 
### **설명 가능한 AI(XAI) 통합**
평가 결과에 대한 사용자 신뢰와 이해도를 높이기 위해 설명 가능한 AI 접근법을 통합: 

- **시각적 하이라이트** : 문제적 표현에 색상 코드화된 하이라이트 적용 
- **근거 기반 설명** : 각 감점 항목에 대해 "이 표현이 왜 문제인지"를 명확히 설명. 
- **개선 제안** : 대안적 표현 방식과 구체적인 개선 방향 제시. 
- **규범 연계** : 관련 언론 윤리 규범과 원칙을 연결하여 평가의 정당성 강화. 
## **6-3-3. 실용성 제고를 위한 하이브리드 접근법** 
'외부 요인' 분석을 위해 지도학습(supervised learning)과 비지도학습(unsupervised learning)을 결합한 방식을 제안함. 정치적 편향성 감지에는 BERT 모델을 fine-tuning한 텍스트 분류기를, 상업적 영향력 분석에는 토픽 모델링(topic modeling) 기법을 동시에 적용한다. 

# **7. 프롬프트 기반 평가 시스템 구현** 
기사 품질을 평가하는 AI 시스템을 어떻게 실제로 구현할 것인지 설명하는 섹션입니다. 여기서는 '프롬프트 기반 접근법'을 채택했는데, 이는 AI에게 구체적인 지시문(프롬프트)을 제공해 기사를 평가하게 하는 방식입니다. 

이 섹션에서는 AI에게 어떤 내용을 어떻게 지시할지(프롬프트 템플릿), 다양한 AI 모델(ChatGPT, Claude 등)에 맞게 어떻게 최적화할지, 그리고 이 시스템을 사용자들이 쉽게 접근할 수 있도록 깃허브(GitHub Pages)와 디스코드(Discord) 커뮤니티를 어떻게 구축할지 설명합니다. 

또한 사용자들이 평가한 결과를 수집하고, 이 데이터를 활용해 시스템을 지속적으로 개선하는 방법도 다룹니다. 초기에는 전문가 검증 데이터 300개(LLM 성능 개선으로 점차 더 적은 횟수로 학습이 가능해지고 있습니다)로 시작해 점차 시민 참여 데이터를 추가하며, 장기적으로는 한국어 기사에 특화된 AI 모델을 개발하기 위한, 학습 데이터 구축 전략까지 제시합니다. 
## **7-1. 프롬프트 템플릿 구조 설계** 
CR 프로젝트의 핵심 평가 기준을 반영한 표준화된 프롬프트 템플릿을 개발: 

- **지시문** : 뉴스 기사의 품질과 신뢰성을 평가하는 전문가 역할 부여 
- **평가 절차** : 기사 유형 확인, 문제적 패턴 탐지, 감점 적용, 결과 제시 등 단계적 지침 
- **평가 차원** : 8개 핵심 평가 영역(진실성과 정확성, 투명성과 책임성 등) 명시 
- **문제적 패턴 탐지** : 무주체 피동형 표현, 익명 취재원 남용 등 주요 패턴 식별 지침 
- **점수 산출 방식** : 0점을 기준점으로 하여 문제 패턴 발견 시 마이너스 점수 부여 (문제가 없는 기사 = 0점, 문제가 많을수록 더 낮은 마이너스 점수) 
- **출력 형식** : 종합 점수, 차원별 점수, 발견된 패턴, 개선 제안 등을 포함한 표준화된 결과 형식 
## **7-2. 다양한 LLM 최적화 버전 개발** 
프롬프트 성능을 극대화하기 위해 주요 LLM별 최적화 버전을 개발: 

- **ChatGPT 최적화 버전** : GPT-4의 맥락 이해 능력과 복잡한 지시 처리 능력에 최적화 
- **Claude 최적화 버전** : Claude의 긴 맥락 윈도우와 객관적 평가 성향에 최적화 
- **Gemini 최적화 버전** : Google Gemini의 특성에 맞춘 지시 형식과 출력 구조 조정 
## **7-3. GitHub Pages 안내 사이트 구축** 
사용자 접근성을 높이기 위한 정보 허브로서 GitHub Pages 기반 안내 사이트를 구축: 

- **사이트 구조** : 홈, 프로젝트 소개, 평가 도구 사용법, 템플릿 다운로드, 결과 제출, FAQ, 커뮤니티 등 직관적 메뉴 구성 
- **주요 콘텐츠** : 
  - 단계별 사용 가이드와 스크린샷 
  - 다양한 AI 플랫폼별 최적화 템플릿 다운로드 
  - Google Forms 기반 평가 결과 제출 시스템 
  - 대화형 데모와 결과 시각화 예시 
- **디자인** : 미니멀리즘, 가독성 중심, 뉴스 기사처럼 신뢰감 있는 디자인, 반응형 설계 
## **7-4. Discord 커뮤니티 구축** 
평가 결과 공유와 토론을 위한 Discord 커뮤니티 플랫폼을 구축: 

- **채널 구조** : 
  - 정보 카테고리: #환영합니다, #공지사항, #자주-묻는-질문, #리소스-센터 
  - 커뮤니티 카테고리: #일반-대화, #미디어-이슈, #제안-피드백 
  - 평가 결과 카테고리: #평가-결과-공유, #우수-평가, #평가-토론, #문제적-기사 
  - 프롬프트 개발 카테고리: #프롬프트-피드백, #프롬프트-실험실, #특화-프롬프트 
  - 데이터 & 연구 카테고리: #데이터-분석, #연구-협업, #AI-개발-논의 
- **자동화 봇 활용** : 평가 결과 제출 봇, 주간 요약 봇, 환영 봇 등 운영 효율화 
## **7-5. 데이터 수집 체계 구축** 
평가 데이터를 체계적으로 수집하기 위한 인프라를 구축합니다: 

- **Google Forms 기반 제출 시스템** : 표준화된 양식으로 평가 결과와 메타데이터 수집 
- **데이터 처리 파이프라인** : 수집된 데이터의 자동 검증, 정제, 구조화, 익명화 과정 
- **단계별 데이터 목표** : 
  - 초기: 전문가 검증 데이터 300개 
  - 중기: 시민 참여 데이터 700개 추가 (총 1,000개) 
  - 장기: 지속적 데이터 품질 향상 및 다양성 확대 
## **7-6. 평가 데이터 활용 전략** 
시민 참여로 수집된 데이터를 모델 개발에 효과적으로 활용하기 위한 전략을 수립함: 

- **데이터 품질 관리** : 전문가 리뷰를 통한 샘플 검증, 이상치 감지, 일관성 확인 
- **하이브리드 데이터셋 구축** : 시민 참여 데이터 + 전문가 주석 데이터 + 룰 기반 자동 태깅 데이터 결합 
- **점진적 모델 개발** : 명확한 패턴 탐지(무주체 피동형, 익명 취재원 등)부터 시작해 복잡한 요소(편향성 등)로 확장 
## **7-7. 학습 데이터 구축 전략**(Track 2 준비)
미래의 AI 모델 개발을 위한 고품질 학습 데이터셋 구축 전략을 수립합니다: 

- **계층적 샘플링** : 
  - 언론사 유형, 정치적 성향, 주제, 기사 형식을 고려한 층화추출 
  - 시간적 분포를 고려한 최소 3년 이상의 기간 데이터 포함 
- **공공 데이터 활용** : 
  - [국립국어원의 '신문 말뭉치' 코퍼스](https://kli.korean.go.kr/corpus/main/requestMain.do)
  - [AI허브의 '뉴스 기사 기계독해 데이터' 활용](https://www.aihub.or.kr/aihubdata/data/list.do?pageIndex=1&currMenu=115&topMenu=100&dataSetSn=&srchdataClCode=DATACL001&srchDataRealmCode=REALM002&searchKeyword=%EB%89%B4%EC%8A%A4&srchDetailCnd=DETAILCND001&srchOrder=ORDER001&srchPagePer=20)
  - [한국신문윤리위원회 심의 자료 분석](https://www.ikpec.or.kr/m2/sub2_1.asp)
  - [한국어 형태소 분석기 '바른'](https://bareun.ai/)
- **반자동 레이블링 파이프라인** : 
  - 규칙 기반 초기 자동 레이블링 → 전문가 검증 → 다중 평가자 교차 검증 
  - 수작업 레이블링 대비 약 70% 시간 절약 가능한 효율적 접근법 
- **한국어 기사 특화 데이터 증강 기법** : 
  - 구문 변형: 동일 의미의 문장 구조 변형(능동↔피동, 직접↔간접 인용) 
  - 취재원 익명화/명시화 변환: 실명↔익명 취재원 변환으로 학습 쌍 생성 
  - 기사 길이 조정: 핵심 정보 유지하며 다양한 길이의 샘플 생성 
- **편향 최소화 전략** : 
  - 블라인드 레이블링: 언론사명과 기자명을 가린 상태에서 평가 
  - 다중 평가자: 다양한 배경의 평가자를 통한 교차 검증 
  - 명확한 평가 지침: 객관적 지표 중심의 상세 가이드라인 제공 

# **8. 기사 심층성 평가 시스템** 
기사의 품질을 평가할 때 단순히 문제점을 찾아내는 것을 넘어, 기사가 얼마나 '깊이 있게' 작성되었는지도 중요하게 살펴야 합니다. 이 섹션에서는 기사의 심층성, 즉 얼마나 풍부한 맥락과 정보를 제공하는지를 평가하는 시스템을 설명합니다. 

기존에는 기사의 심층성을 평가하는 것이 주관적이고 어렵다고 여겨졌지만, 최신 AI 기술을 활용하면 이를 정량적으로 측정할 수 있습니다. 예를 들어, 기사가 단순히 '무슨 일이 일어났는지'만 알려주는 것이 아니라 '왜 일어났는지(원인)', '어떻게 진행되었는지(과정)', '어떤 결과를 가져왔는지', 그리고 '앞으로 어떻게 될지(전망)'까지 포함하고 있는지를 AI가 분석할 수 있습니다. 

또한 이 시스템은 기사에 등장하는 다양한 정보(인물, 조직, 장소 등)의 관계를 네트워크로 분석하고, 문장별 정보 밀도를 시각화하여 보여줍니다. 이를 통해 기자들은 자신의 기사가 어떤 부분에서 깊이가 부족한지 알고 개선할 수 있습니다. 
## **8-1. 심층적 기사 분석을 위한 핵심 기술** 
### **8-1-1. 문장 단위 의미 분석**
기존의 문단 단위 분석에서 벗어나 문장 단위로 더 정확한 의미 분석을 수행한다. 이는 기사의 문맥 일관성(coherence) 평가와 세그먼트별 역할 분석(도입부→원인, 본문→과정, 후반부→결과, 결론→전망)을 가능하게 한다. 

def \_get\_sentence\_embeddings(self, sentences):

`  `embeddings = []

`  `for sentence in sentences:

`    `# 문장 임베딩 생성

`    `outputs = self.sentence\_model(\*\*inputs)

`    `embedding = outputs.last\_hidden\_state.mean(dim=1).squeeze().numpy()

`    `embeddings.append(embedding)

`  `return np.array(embeddings)
### **8-1-2. 그래프 기반 맥락 분석**
맥락 정보를 그래프 구조로 표현하여 분석한다. 문장, 개체, 키워드를 노드로, 이들 간의 관계를 엣지로 표현하여 정보의 연결성과 맥락 제공 수준을 평가한다. 

def \_build\_context\_graph(self, text, sentences):

`  `G = nx.DiGraph()

`  `# 문장을 노드로 추가

`  `for i, sent in enumerate(sentences):

`    `G.add\_node(i, text=sent, type='sentence')

`  `# 개체와 키워드 추출 및 관계 설정

`  `entities = [(ent.text, ent.label\_) for ent in self.nlp(text).ents]

`  `# 문장-개체 간 관계 설정

`  `for sent\_idx, sent in enumerate(sentences):

`    `for entity\_idx, (entity, \_) in enumerate(entities):

`      `if entity.lower() in sent.lower():

`        `G.add\_edge(sent\_idx, f"entity\_{entity\_idx}", type='contains')

`  `return G
### **8-1-3. 의미적 중요도 기반 정보 밀도 분석**
단순한 단어 빈도가 아닌 의미론적 중요도에 기반한 키워드 추출 및 문장별 정보 밀도를 분석한다. KeyBERT 모델을 활용해 키워드를 추출하고, 문장 간 의미적 유사성 분석을 통해 다양성을 측정한다. 
### **8-1-4. 개체 관계 네트워크 분석**
기사에 등장하는 개체들(인물, 조직, 장소 등) 간의 관계를 네트워크로 모델링하고, 중심성 분석을 통해 중요 개체를 식별한다. 이를 통해 기사가 다양한 시각과 정보원을 포함하고 있는지 평가한다. 
## **8-2. 다차원 평가 프레임워크** 
기사의 심층성을 다음 네 가지 핵심 차원에서 평가: 

1. **구조적 완전성** : 원인-과정-결과-전망의 4단계 구조를 얼마나 갖추었는지 평가 
- **맥락 제공 수준** : 배경 설명, 역사적 참조, 비교 요소, 시간 참조 표현 등을 분석 
- **정보 밀도와 다양성** : 문장별 정보 밀도, 키워드 다양성, 의미적 다양성 측정 
- **개체 포괄성** : 인물, 조직, 장소, 시간 등 다양한 개체 유형을 포함하는지 평가 

각 차원별 점수를 종합하여 최종 심층성 점수(100점 만점)를 산출하며, 분석의 신뢰도 점수도 함께 제공한다. 
## **8-3. 사용자 친화적 결과 시각화 및 개선 제안** 
분석 결과를 직관적인 시각화 요소를 포함한 HTML 리포트로 제공한다: 

- 문장별 정보 밀도 히트맵 
- 개체 유형별 태그 클라우드 
- 구조 요소별 문제점 하이라이트 
- 카테고리별 구체적 개선 제안 

이를 통해 단순한 점수 제공을 넘어, 기사 작성자에게 실질적인 개선 방향을 제시('개선 제안' 옵션으로, 결과 리포트에 표시 여부를 선택할 수 있게할 것). 
## **8-4. 구현 로드맵** 
본 시스템은 다음 단계에 따라 개발: 

- **Phase 1** : 핵심 모듈 프로토타입 개발 
- **Phase 2** : 인간 평가와의 상관관계 분석, 분야별 모델 튜닝 
- **Phase 3** : 자동 개선 제안 엔진 고도화 
- **Phase 4** : 오픈 API 서비스 런칭 및 다양한 플랫폼 통합 

이러한 기사 심층성 평가 시스템은 CR 프로젝트의 다차원 매트릭스 기반 평가 시스템을 한층 강화하며, 객관적 지표를 통해 저널리즘 품질 향상에 기여할 것임. 

# **9. 유형별 맞춤 평가** 
모든 기사가 같은 기준으로 평가되어서는 안 됩니다. 스트레이트 뉴스, 해설 기사, 탐사 보도 등 기사의 유형에 따라, 또 정치, 경제, 과학 등 다루는 주제에 따라 평가 기준이 달라져야 합니다. 이 섹션에서는 각 기사의 특성에 맞게 평가 기준을 차별화하는 '유형별 맞춤 평가' 시스템을 설명합니다. 

예를 들어, 스트레이트 뉴스에서는 5W1H(누가, 언제, 어디서, 무엇을, 어떻게, 왜)의 충실한 전달과 객관성이 중요하지만, 해설 기사에서는 맥락 제공과 다양한 관점 제시가 더 중요합니다. 또한 같은 문제적 패턴이라도 기사 유형에 따라 감점 정도를 다르게 적용합니다. 주관적 표현은 스트레이트 뉴스에서는 큰 문제지만, 칼럼에서는 문제가 되지 않습니다. 

이러한 맞춤형 평가를 통해 각 기사의 목적과 특성에 맞는 의미 있는 품질 평가가 가능해지며, 기자들에게도 더 구체적이고 유용한 피드백을 제공할 수 있습니다. 
## **9-1. 계층적 평가 구조 설계** 
각 기사의 특성에 맞는 정밀한 평가를 위해 계층적 평가 구조를 적용한다. 
### **9-1-1. 공통 평가 요소(Core Criteria)**
모든 기사에 적용되는 기본적인 평가 요소. 

- **취재원의 다양성과 투명성** : 취재원 수, 익명 취재원 비율, 소속 명시 등 
- **정보의 정확성** : 사실 확인, 오류 여부, 데이터 신뢰성 등 
- **객관적 서술** : 피동형 표현, 주관적 술어 사용 여부 등 
- **사실과 의견의 구분** : 보도와 논평의 명확한 분리 여부 
- 기본 점수(100점)에서 문제 패턴 발견 시 감점 방식 적용 
### **9-1-2. 유형별 평가 요소(Type-specific Criteria)**
기사의 유형에 따라 차별화된 평가 기준을 적용한다. 

- **스트레이트 뉴스** : 5W1H 충실도, 신속성, 정확성 중점 
- **해설/분석 기사** : 맥락 제공, 인과관계 설명, 다양한 관점 제시 
- **탐사 보도** : 공익성, 증거 제시, 추적 심도, 윤리적 취재 방식 
### **9-1-3. 분야별 평가 요소(Domain-specific Criteria)**
기사가 다루는 주제 영역에 따른 특화된 평가 기준. 

- **정치 기사** : 권력 감시, 정파성 배제, 정책 중심 보도 
- **경제 기사** : 데이터 정확성, 경제적 영향 분석, 전문 용어 설명 
- **과학 기사** : 과학적 근거, 전문가 검증, 대중적 설명, 과장 배제 
### **9-1-4. 상황/이벤트별 평가 요소(Context-specific Criteria)**
특정 시간적 맥락이나 이벤트에 따른 평가 기준. 

- **국정감사 기사** : 질의응답 맥락 유지, 주요 이슈 커버리지, 불필요한 정쟁 배제 
- **재난 보도** : 정보 정확성, 피해자 인권 보호, 추측 보도 지양 
- **선거 보도** : 후보자 간 균형, 여론조사 방법론 투명성 
## **9-2. 가중치 기반 동적 평가 시스템** 
유형, 분야, 시기에 따라 평가 항목별 가중치를 동적으로 조정하는 시스템을 구현: 

\# 예시 코드 (의사 코드)

if 유형 == "스트레이트" and 분야 == "정치":

`  `가중치 = {"사실검증": 1.5, "취재원투명성": 1.3, "균형성": 1.2}

elif 유형 == "해설" and 분야 == "경제":

`  `가중치 = {"맥락제공": 1.4, "데이터정확성": 1.5, "전문용어설명": 1.3}
### **9-2-1. 동적 가중치 조정 메커니즘**
평가 시스템은 기사의 특성을 자동으로 인식하고 적절한 가중치를 선택한다: 

- **자동 유형 분류** : 제목, 본문 구조, 언어 패턴 등을 분석해 기사 유형 자동 분류 
- **주제 인식** : 키워드, 개체명, 주제 모델링을 통한 기사 주제 분야 인식 
- **시기적 맥락 파악** : 발행일, 언급된 이벤트 등을 통해 시기적 맥락 인식 
- **가중치 매트릭스 적용** : 위 요소들의 조합에 따른 최적 가중치 매트릭스 선택 
### **9-2-2. 기사 유형별 차별화된 감점 체계**
같은 문제적 패턴이라도 기사 유형에 따라 감점의 정도를 차별화: 

- **스트레이트 뉴스에서의 주관적 표현** : 높은 감점(-15점) 
- **해설 기사에서의 주관적 표현** : 중간 감점(-8점) 
- **칼럼에서의 주관적 표현** : 감점 없음(0점) 
### **9-2-3. 평가 결과 맞춤형 표현**
평가 결과 리포트도 기사 유형에 맞게 차별화하면 좋을 것: 

- **스트레이트 뉴스** : "사실 보도의 정확성과 균형성" 중심 피드백 
- **해설 기사** : "맥락 제공과 다양한 관점 제시" 중심 피드백 
- **탐사 보도** : "증거의 충분성과 공익적 가치" 중심 피드백 

이러한 맞춤형 평가 체계를 통해 단순히 모든 기사를 동일한 잣대로 평가하는 것이 아니라, 각 기사의 특성과 목적에 맞는 의미 있는 품질 평가가 가능해집니다. 
