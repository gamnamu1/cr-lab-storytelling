# Story 064: AI의 한계

**화두**: "언론윤리규범을 모두 준수하면서, (동시에) 나쁜 뉴스일 수 있는가?"
**문제적 보도 관행**: 시간적 맥락 무시, 의도적 인상 조작 (AI가 탐지 불가능한 영역)
**시점**: 1인칭 현재형
**배경**: 홈 오피스, CR 프로젝트 베타 테스트
**주인공**: 최서현 (29세, 데이터 과학자)

---

토요일 밤 11시.

노트북 앞에 앉아 있다. 화면에는 코드가 가득하다. 파이썬. CR 프로젝트 AI 평가 알고리즘.

나는 3주 전에 CR 프로젝트 자원봉사에 합류했다. 데이터 과학자. 회사에서는 추천 알고리즘을 만든다. 밤에는 CR 프로젝트를 한다.

알림음. 슬랙 메시지다.

**익명5271**: @서현님, 급해요. 이 기사 좀 봐주세요.

파일이 첨부되어 있다. 기사 URL.

클릭한다.

**제목**: "김○○ 의원, 20년 전 '독재 옹호' 발언 재조명"

기사를 읽는다.

> 야당 김○○ 의원(52)의 과거 발언이 논란이 되고 있다. 김 의원은 2004년 한 토론회에서 "경제 발전을 위해서는 강력한 리더십이 필요하다"며 "60-70년대 개발 독재가 필요악이었다"고 발언한 바 있다.
>
> 당시 토론회 녹취록에 따르면, 김 의원은 "민주주의보다 경제가 우선"이라는 취지의 발언을 여러 차례 했다.
>
> 김 의원은 당시 대학원생이었으며, 보수 성향 연구 모임에서 활동했다.
>
> 김 의원 측은 "20년 전 학생 시절 발언을 문제 삼는 것은 부적절하다"며 "현재는 생각이 다르다"고 해명했다.
>
> 그러나 시민단체 ○○연대는 "과거 발언이 그의 본질을 보여준다"며 "의원직을 사퇴해야 한다"고 주장했다.

기사 끝.

슬랙 메시지가 또 온다.

**익명5271**: 이 기사, 명백히 나쁜 기사 아닙니까? 그런데 AI 평가 결과가 93점 나왔어요.

내 알고리즘으로 분석해본다.

**CR AI 평가 결과**

- 진실성과 정확성: 95점 (사실 확인 완료, 인용 정확)
- 투명성과 책임성: 98점 (실명 취재원, 주체 명확)
- 균형성과 공정성: 88점 (김 의원 해명 포함, 시민단체 의견 포함)
- 인권과 프라이버시: 90점 (공인이므로 과거 발언 보도 가능)
- 전문성과 심층성: 92점 (녹취록 확인, 배경 설명)
- 언어와 표현: 95점 (과장 표현 없음, 주관적 술어 최소)

**종합 점수: 93점**

나는 고개를 갸웃한다. 익명5271 말이 맞다. 이 기사는 뭔가 이상하다. 그런데 AI는 93점을 줬다.

뭐가 문제인가?

기사를 다시 읽는다. 천천히.

---

문제를 발견한다.

**시간**.

김 의원의 발언은 **20년 전**이다. 2004년. 그는 당시 대학원생이었다. 지금은 52세 의원이다.

기사는 20년 전 발언을 지금 문제 삼는다. 해명도 있다. "현재는 생각이 다르다"고.

그러나 기사 구조상, 독자는 "김 의원이 지금도 독재를 옹호한다"는 인상을 받는다.

이게 공정한가?

나는 코드를 연다. 새로운 규칙을 추가하려 한다.

**시도 1: 시간적 맥락 분석**

```python
def check_temporal_context(article):
    # 인용문 날짜 추출
    quote_date = extract_date_from_quote(article)

    # 보도 날짜
    publish_date = article.publish_date

    # 시간 차이 계산
    time_diff = (publish_date - quote_date).years

    # 10년 이상이면 감점
    if time_diff >= 10:
        return -10
    return 0
```

테스트해본다.

그런데 문제가 생긴다. 10년 전 범죄는? 10년 전 성폭력은? 10년 전 횡령은?

그것들도 감점해야 하나? 아니다. 범죄는 시효가 있다. 보도해야 한다.

그럼 기준은? 범죄와 의견을 어떻게 구분하나?

코드로는 불가능하다.

**시도 1 실패**.

---

**시도 2: 공정성 지표**

```python
def check_fairness_score(article):
    # 긍정 발언 vs 부정 발언 비율
    positive_quotes = count_positive_quotes(article)
    negative_quotes = count_negative_quotes(article)

    ratio = positive_quotes / (negative_quotes + 1)

    # 비율이 1:3 이상 차이나면 불공정
    if ratio < 0.33 or ratio > 3.0:
        return -15
    return 0
```

테스트해본다.

또 문제. 실제로 나쁜 사람을 비판하는 기사는? 부정 발언이 많을 수밖에 없다.

예: 성범죄자 보도. 당연히 부정 발언이 많다. 그런데 이 알고리즘은 감점한다.

**시도 2 실패**.

---

**시도 3: 의도 분석**

```python
def check_political_intent(article):
    # 기사 발행 타이밍 분석
    # 해당 정치인 관련 최근 이슈와 상관관계

    recent_news = get_recent_news_about_person(article.subject)

    # 최근 긍정적 뉴스가 있었는가?
    if has_positive_news_recently(recent_news):
        # 과거 부정 발언을 지금 다루는 것은 의도적 공격일 가능성
        return -20
    return 0
```

테스트해본다.

문제: 상관관계와 인과관계를 구분할 수 없다.

우연의 일치일 수도 있다. 정말 최근에 과거 녹취록이 발견됐을 수도 있다.

AI는 **의도**를 판단할 수 없다.

**시도 3 실패**.

---

3주가 지났다. 나는 10가지 방법을 시도했다. 모두 실패했다.

슬랙에 메시지를 쓴다.

**서현**: @기획자M, 통화 가능하십니까?

1분 후, 답장.

**기획자M**: 네, 지금 가능합니다. 줌 링크 보내드릴게요.

화상 통화가 시작된다. 기획자M의 얼굴이 화면에 뜬다. 40대 정도. 피곤해 보인다. 그러나 눈빛은 날카롭다.

"서현님, 무슨 일이세요?"

"M님, 제가 3주간 매달렸는데, 답이 없어요."

"무슨 문제입니까?"

나는 익명5271이 제기한 기사를 공유한다. 그리고 내가 시도한 방법들을 설명한다.

M은 듣는다. 끄덕인다. 중간에 끊지 않는다.

내 설명이 끝난다.

M이 말한다.

"서현님, 제가 질문 하나 할게요."

"네."

"CR 프로젝트가 AI 평가 플랫폼이라고 생각하세요?"

나는 당연하다는 듯 답한다.

"...아닌가요? AI로 기사를 분석하는 거잖아요."

M이 웃는다. 쓴웃음.

"아니에요. AI는 도구일 뿐입니다. 주체는 시민이에요."

"무슨 뜻입니까?"

M이 화면을 공유한다. CR 프로젝트 웹사이트. 기사 평가 페이지.

"보세요. AI 점수 아래에 뭐가 있습니까?"

화면을 본다.

**AI 평가: 93점**

그 아래:

**시민 평가: 42점** (투표 참여자 127명)

**댓글 132개**

댓글을 읽는다.

- "20년 전 발언을 지금 문제 삼는 건 불공정하다" (공감 45)
- "사람은 변할 수 있다. 과거에 매몰되지 말자" (공감 38)
- "김 의원이 사과하고 입장 바뀐 걸 기사가 충분히 다뤄야 한다" (공감 29)

M이 말한다.

"AI는 명백한 규범 위반을 찾아줍니다. 무주체 피동형, 익명 취재원 남용, 추측성 표현. 이런 건 패턴으로 잡혀요."

"네."

"그러나 미묘한 왜곡, 의도적 선택, 시간적 맥락, 이런 건 사람만 판단할 수 있어요."

M이 다른 예시를 보여준다.

"지난주에 이런 케이스가 있었어요. AI 점수 91점, 시민 평가 38점."

기사를 본다. 한 연예인의 10년 전 음주운전 기록을 다룬 기사다. 지금 그 연예인이 교통안전 캠페인 모델로 선정됐다는 이유로.

M이 설명한다.

"AI는 '사실이다, 공인이다, 공익적이다'라고 판단했어요. 93점. 그런데 시민들은 '10년 전 일을 지금 들춰내는 건 불공정하다, 그 사람은 벌금 냈고 면허 정지 받았다, 이미 처벌 받았다'고 평가했어요. 38점."

나는 이해한다.

"그러니까... AI는 첫 단계일 뿐이고, 실제 평가는 시민이 하는 거군요."

"정확합니다."

M이 계속한다.

"서현님, 서현님이 한 작업이 의미 없는 게 아니에요. 오히려 핵심이에요."

"어떻게요?"

"AI의 한계를 명확히 하는 것. 그래야 시민들이 어디에 집중해야 할지 알아요."

M이 새로운 화면을 보여준다.

"제안이 있어요. '서현님의 발견'을 기능으로 만들면 어떨까요?"

"무슨 기능입니까?"

"'AI 판단 불가 영역 표시' 기능."

M이 목업을 보여준다.

**AI 평가: 93점**

⚠️ **AI가 판단할 수 없는 요소**:
- 시간적 맥락 공정성 (20년 전 발언을 지금 보도하는 것의 적절성)
- 보도 타이밍 (정치적 의도 가능성)
- 인물 변화 고려 (현재 입장과의 괴리)

**시민 평가 필요 영역**:
- 이 기사가 정치적 의도로 작성되었는지
- 20년 전 발언을 지금 다루는 것이 공정한지
- 인물의 변화를 충분히 반영했는지

나는 화면을 본다. 입이 벌어진다.

"이거... 완벽한데요."

"서현님이 3주간 고민한 게 이거잖아요. AI가 뭘 못하는지. 그걸 명시적으로 보여주는 거예요."

"그럼 시민들이 그 부분을 판단하는 거군요."

"맞습니다. AI와 시민의 협업. AI는 객관적으로 판단 가능한 영역을 담당하고, 시민은 주관적 판단이 필요한 영역을 담당해요."

나는 코드 에디터를 연다. 아이디어가 떠오른다.

"M님, 제가 이 기능 구현해볼게요."

"정말요?"

"네. AI가 자신의 한계를 스스로 인식하고, 사용자에게 알려주는 거. 메타-AI랄까요."

M이 웃는다. 진짜 웃음.

"서현님, 완벽합니다. 이게 바로 우리가 만들려는 거예요."

---

통화가 끝난다.

나는 코드를 쓰기 시작한다.

```python
class MetaAI:
    """
    AI의 판단 한계를 인식하고 표시하는 모듈
    """

    def identify_judgment_limits(self, article):
        limits = []

        # 시간적 맥락 체크
        if self._has_old_quotes(article):
            limits.append({
                'category': '시간적 맥락 공정성',
                'description': '과거 발언을 현재 보도하는 적절성',
                'ai_limitation': 'AI는 시간의 흐름에 따른 인물 변화를 판단할 수 없습니다',
                'citizen_question': '이 발언이 현재도 유효하다고 생각하십니까?'
            })

        # 정치적 타이밍 체크
        if self._suspicious_timing(article):
            limits.append({
                'category': '보도 타이밍',
                'description': '특정 시점에 과거 사안을 다루는 의도',
                'ai_limitation': 'AI는 우연과 의도를 구분할 수 없습니다',
                'citizen_question': '이 기사가 정치적 의도로 작성되었다고 생각하십니까?'
            })

        return limits
```

코드를 쓰다가 멈춘다.

웃음이 난다.

3주 전 나는 "AI로 모든 걸 해결하려" 했다. 완벽한 알고리즘. 모든 나쁜 기사를 걸러내는 마법 같은 코드.

그러나 그건 불가능하다.

AI는 도구다. 주체는 사람이다.

중요한 건 AI가 얼마나 똑똑한가가 아니라, AI와 사람이 어떻게 협력하는가다.

나는 다시 타이핑을 시작한다.

---

일주일 후.

슬랙 메시지.

**익명5271**: @서현님, 새 기능 대박이에요! AI가 자기가 못 판단하는 걸 솔직하게 말해주니까, 오히려 더 믿음이 가요.

**익명7823**: 동의합니다. 전에는 AI 점수만 보고 판단했는데, 이제는 '시민 평가 필요 영역'을 보고 제가 직접 생각해보게 돼요.

**기획자M**: @서현님, 정말 훌륭한 작업이었습니다. 이게 CR 프로젝트의 다음 단계예요. AI와 시민의 협업.

나는 화면을 본다. 웃는다.

AI의 한계를 인정하는 것.

그게 더 나은 AI를 만드는 길이었다.

---

**(작성일: 2025년 11월 24일)**
**(분량: 6,892자)**

