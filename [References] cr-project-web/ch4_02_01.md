# **2-1. CR 플랫폼 구조 설계** 
## **프로젝트 개요** 
CR 프로젝트는 AI 기반으로 기사의 품질을 정량적으로 측정하는 웹앱 플랫폼입니다. 플랫폼 구축을 위해 두 가지 주요 접근법(상용 AI API 활용 또는 오픈소스 LLM 파인튜닝)을 고려하여, 유연하고 확장 가능한 아키텍처를 설계합니다. 
## **접근법 비교** 

|항목 |상용 API 사용 |오픈소스 LLM 파인튜닝 |
| :- | :- | :- |
|초기 개발 속도 |빠름 (API 연동 코드만 필요) |느림 (모델 학습 및 파인튜닝 필요) |
|비용 구조 |사용량 기반 종량제 과금 (API 호출당 비용) |초기 개발 및 인프라 비용 + 운영 비용 |
|커스터마이징 |제한적 (프롬프트 엔지니어링 수준) |높음 (모델 자체 파인튜닝 가능) |
|독립성 |낮음 (외부 서비스 의존) |높음 (자체 호스팅 가능) |
|데이터 프라이버시 |제한적 (데이터 외부 전송) |높음 (자체 인프라에서 처리) |
|확장성 |API 제한에 종속 |인프라 규모에 따라 자유롭게 확장 가능 |
|유지보수 부담 |낮음 (API 제공사가 모델 관리) |높음 (모델 및 인프라 자체 관리) |
|최적화 시나리오 |MVP 빠른 구축, 검증 단계 |대규모 서비스, 특화된 요구사항 있는 환경 |
## **파일 트리 구조** 
### **1. 상용 AI API 사용 시나리오**
cr-platform/

├── frontend/                    # 프론트엔드 애플리케이션

│   ├── public/                  # 정적 파일

│   │   ├── index.html          # 메인 HTML

│   │   ├── favicon.ico         # 파비콘

│   │   └── assets/             # 이미지, 폰트 등 자산

│   ├── src/

│   │   ├── components/         # UI 컴포넌트

│   │   │   ├── common/         # 공통 컴포넌트(헤더, 푸터 등)

│   │   │   ├── analysis/       # 분석 관련 컴포넌트

│   │   │   │   ├── UrlInput.jsx          # URL 입력 컴포넌트

│   │   │   │   ├── TextInput.jsx         # 텍스트 입력 컴포넌트

│   │   │   │   ├── FileUpload.jsx        # 파일 업로드 컴포넌트

│   │   │   │   ├── AnalysisProgress.jsx  # 분석 진행 표시

│   │   │   │   ├── ResultSummary.jsx     # 요약 결과 표시

│   │   │   │   └── ArticleHighlight.jsx  # 문제 표현 하이라이트

│   │   │   ├── visualization/  # 시각화 컴포넌트

│   │   │   │   ├── RadarChart.jsx        # 레이더 차트

│   │   │   │   ├── ScoreBar.jsx          # 점수 막대 차트

│   │   │   │   └── PatternList.jsx       # 패턴 리스트

│   │   │   └── user/           # 사용자 관련 컴포넌트

│   │   ├── pages/	# 페이지 컴포넌트

│   │   │   ├── Home.jsx               # 홈페이지

│   │   │   ├── Analysis.jsx           # 분석 페이지

│   │   │   ├── Results.jsx            # 결과 페이지

│   │   │   ├── History.jsx            # 분석 이력 페이지

│   │   │   └── About.jsx	# 소개 페이지

│   │   ├── services/           # API 연동 서비스

│   │   │   ├── api.js                 # API 클라이언트

│   │   │   ├── auth.js                # 인증 서비스

│   │   │   └── analysis.js            # 분석 관련 API

│   │   ├── context/            # 상태 관리

│   │   │   ├── AuthContext.js         # 인증 컨텍스트

│   │   │   └── AnalysisContext.js     # 분석 컨텍스트

│   │   ├── utils/	# 유틸리티 함수

│   │   │   ├── formatters.js          # 포맷팅 함수

│   │   │   └── validators.js          # 검증 함수

│   │   ├── App.jsx             # 메인 앱 컴포넌트

│   │   └── index.jsx           # 진입점

│   ├── package.json            # 의존성 정의

│   ├── vite.config.js          # Vite 설정 (또는 webpack.config.js)

│   └── .env.example            # 환경 변수 예시

├── backend/                     # 백엔드 애플리케이션

│   ├── app/                     # 애플리케이션 소스 디렉토리

│   │   ├── api/                 # API 엔드포인트 모듈들

│   │   │   ├── \_\_init\_\_.py

│   │   │   ├── auth.py          # 인증 관련 라우트 정의

│   │   │   ├── ai.py            # AI 기능 관련 라우트

│   │   │   └── user.py          # 사용자 관련 라우트

│   │   ├── models/	# 데이터베이스 ORM 모델

│   │   │   ├── \_\_init\_\_.py

│   │   │   ├── user.py          # User 테이블 모델

│   │   │   ├── analysis.py      # 분석 결과 모델

│   │   │   └── article.py       # 기사 모델

│   │   ├── schemas/             # Pydantic 스키마

│   │   │   ├── \_\_init\_\_.py

│   │   │   ├── user.py          # 사용자 관련 스키마

│   │   │   ├── analysis.py      # 분석 관련 스키마

│   │   │   └── article.py       # 기사 관련 스키마

│   │   ├── services/            # 비즈니스 로직 서비스

│   │   │   ├── \_\_init\_\_.py

│   │   │   ├── ai/	# AI 서비스

│   │   │   │   ├── \_\_init\_\_.py

│   │   │   │   ├── anthropic.py # Anthropic Claude API 연동

│   │   │   │   ├── openai.py    # OpenAI API 연동 (선택적)

│   │   │   │   └── prompt.py    # 프롬프트 생성

│   │   │   ├── analysis/        # 분석 서비스

│   │   │   │   ├── \_\_init\_\_.py

│   │   │   │   ├── article.py   # 기사 처리

│   │   │   │   ├── crawler.py   # 웹 크롤링

│   │   │   │   ├── patterns.py  # 패턴 탐지

│   │   │   │   └── report.py    # 분석 보고서 생성

│   │   │   ├── auth.py          # 인증 서비스

│   │   │   └── user.py          # 사용자 서비스

│   │   ├── middlewares/         # 미들웨어

│   │   │   ├── \_\_init\_\_.py

│   │   │   ├── auth.py          # 인증 미들웨어

│   │   │   └── error.py         # 오류 처리 미들웨어

│   │   ├── utils/               # 유틸리티 함수

│   │   │   ├── \_\_init\_\_.py

│   │   │   ├── logger.py        # 로깅 유틸리티

│   │   │   └── response.py      # 응답 형식화

│   │   ├── config.py            # 애플리케이션 설정

│   │   ├── database.py          # 데이터베이스 연결 및 설정

│   │   ├── main.py	# FastAPI 애플리케이션 진입점

│   │   └── \_\_init\_\_.py

│   ├── tests/                   # 백엔드 테스트 코드

│   │   ├── \_\_init\_\_.py

│   │   ├── conftest.py          # pytest 설정

│   │   ├── test\_api/            # API 테스트

│   │   └── test\_services/       # 서비스 테스트

│   ├── alembic/                 # 데이터베이스 마이그레이션

│   │   ├── versions/            # 마이그레이션 버전

│   │   ├── env.py               # Alembic 환경 설정

│   │   └── alembic.ini          # Alembic 설정

│   ├── requirements.txt         # 백엔드 Python 의존성

│   ├── Dockerfile               # 백엔드용 Docker 이미지 설정

│   └── .env.example             # 환경 변수 예시

├── docker/                      # Docker 설정

│   ├── frontend/

│   │   ├── Dockerfile          # 프론트엔드 Docker 설정

│   │   └── nginx.conf          # Nginx 설정

│   ├── backend/

│   │   ├── Dockerfile          # 백엔드 Docker 설정

│   │   └── start.sh            # 시작 스크립트

│   └── nginx/

│       └── nginx.conf          # Nginx 설정

├── infrastructure/	# 인프라 코드

│   ├── terraform/               # Terraform IaC

│   │   ├── main.tf             # 메인 Terraform 설정

│   │   ├── variables.tf        # 변수 정의

│   │   ├── outputs.tf          # 출력 정의

│   │   └── modules/            # Terraform 모듈

│   │       ├── networking/     # 네트워킹 관련 모듈

│   │       ├── compute/        # 컴퓨팅 관련 모듈

│   │       └── database/       # 데이터베이스 관련 모듈

│   ├── aws/                    # AWS 특화 설정

│   │   ├── ecs/                # ECS 관련 설정

│   │   │   └── task-definition.json  # ECS 작업 정의

│   │   ├── s3/                 # S3 관련 설정

│   │   └── rds/                # RDS 관련 설정

│   └── scripts/                # 인프라 스크립트

│       ├── deploy.sh           # 배포 스크립트

│       └── backup.sh           # 백업 스크립트

├── docs/                       # 문서

│   ├── api/                    # API 문서

│   ├── architecture/           # 아키텍처 문서

│   ├── development/            # 개발 가이드

│   └── deployment/             # 배포 가이드

├── scripts/                    # 유틸리티 스크립트

│   ├── setup.sh                # 초기 설정 스크립트

│   └── seed\_db.py	# 데이터베이스 시드 스크립트

├── docker-compose.yml          # 개발용 Docker Compose 설정

├── docker-compose.prod.yml     # 프로덕션용 Docker Compose 설정

├── .env.example                # 루트 환경 변수 예시

├── .gitignore                  # Git 무시 파일 설정

└── README.md                   # 프로젝트 문서
### **2. 오픈소스 LLM 파인튜닝 시나리오**
cr-platform/

├── frontend/                    # (1번 시나리오와 동일)

├── backend/                     # 백엔드 애플리케이션

│   ├── app/                     # (1번 시나리오와 유사)

│   │   ├── api/                 # API 엔드포인트 모듈

│   │   ├── models/	# 데이터베이스 모델

│   │   ├── schemas/             # Pydantic 스키마

│   │   ├── services/            # 서비스 모듈

│   │   │   ├── ai/	# AI 서비스 (수정)

│   │   │   │   ├── \_\_init\_\_.py

│   │   │   │   ├── model\_service.py  # 자체 모델 연동

│   │   │   │   ├── sagemaker.py      # SageMaker 연동

│   │   │   │   └── prompt.py         # 프롬프트 생성

│   │   │   └── ... (1번 시나리오와 유사)

│   │   └── ... (1번 시나리오와 유사)

│   └── ... (1번 시나리오와 유사)

├── ml/                          # 머신러닝/AI 모델 관련 코드

│   ├── data/                    # 데이터 관리

│   │   ├── raw/                 # 원시 데이터

│   │   │   ├── articles/        # 수집된 기사

│   │   │   └── patterns/        # 패턴 예시

│   │   ├── processed/           # 처리된 데이터

│   │   │   ├── train/           # 학습 데이터

│   │   │   ├── validation/      # 검증 데이터

│   │   │   └── test/            # 테스트 데이터

│   │   ├── preprocessing/       # 데이터 전처리

│   │   │   ├── clean\_text.py    # 텍스트 정제

│   │   │   ├── tokenize.py      # 토큰화

│   │   │   └── extract\_features.py  # 특성 추출

│   │   └── labeling/            # 데이터 라벨링

│   │       ├── pattern\_labeler.py    # 패턴 라벨링

│   │       └── dimension\_scorer.py   # 차원별 점수 부여

│   ├── models/                  # 모델 정의

│   │   ├── base\_model/          # 기본 모델

│   │   │   ├── config.json      # 모델 설정

│   │   │   └── model\_loader.py  # 모델 로더

│   │   ├── fine\_tuning/         # 파인튜닝

│   │   │   ├── trainer.py       # 학습 코드

│   │   │   ├── peft\_config.py   # PEFT 설정

│   │   │   └── lora\_config.py   # LoRA 설정

│   │   └── prompts/             # 프롬프트 템플릿

│   │       ├── pattern\_detection.py   # 패턴 탐지 프롬프트

│   │       └── dimension\_scoring.py   # 차원별 점수 프롬프트

│   ├── training/                # 모델 학습

│   │   ├── scripts/             # 학습 스크립트

│   │   │   ├── train.py         # 학습 코드

│   │   │   └── fine\_tune.py     # 파인튜닝 코드

│   │   └── configs/             # 학습 설정

│   │       ├── training\_config.json    # 학습 하이퍼파라미터

│   │       └── fine\_tuning\_config.json # 파인튜닝 설정

│   ├── evaluation/	# 모델 평가

│   │   ├── metrics.py           # 평가 지표

│   │   └── evaluate.py          # 평가 코드

│   ├── deployment/	# 모델 배포

│   │   ├── aws/                 # AWS 배포

│   │   │   ├── sagemaker/       # SageMaker 설정

│   │   │   │   ├── endpoint\_config.json  # 엔드포인트 설정

│   │   │   │   └── deploy.py    # 배포 코드

│   │   │   └── lambda/          # Lambda 함수

│   │   │       ├── handler.py   # Lambda 핸들러

│   │   │       └── package.py   # 패키징 스크립트

│   │   └── docker/	# Docker 설정

│   │       ├── Dockerfile       # ML 모델 Dockerfile

│   │       └── requirements.txt # ML 의존성

│   ├── inference/               # 추론 코드

│   │   ├── preprocessing.py     # 추론 전처리

│   │   ├── postprocessing.py    # 추론 후처리

│   │   └── inference.py         # 추론 코드

│   ├── requirements.txt         # ML 의존성

│   └── README.md                # ML 문서

├── infrastructure/	# (확장된 인프라 코드)

│   ├── terraform/               # Terraform IaC

│   │   ├── ... (1번 시나리오와 유사)

│   │   └── modules/

│   │       ├── ... (1번 시나리오와 유사)

│   │       └── ml/	# ML 인프라 모듈

│   │           ├── sagemaker.tf # SageMaker 리소스

│   │           └── s3.tf        # 모델 저장 S3 리소스

│   ├── aws/

│   │   ├── ... (1번 시나리오와 유사)

│   │   ├── sagemaker/          # SageMaker 관련 설정

│   │   │   ├── inference.py    # 추론 스크립트

│   │   │   └── Dockerfile      # SageMaker 용 Dockerfile

│   │   └── ecr/                # ECR 관련 스크립트

│   │       └── push-images.sh  # 이미지 푸시 스크립트

│   └── ... (1번 시나리오와 유사)

├── docs/                       # (확장된 문서)

│   ├── ... (1번 시나리오와 유사)

│   └── ml/                     # ML 관련 문서

│       ├── model.md            # 모델 설명

│       ├── training.md         # 학습 가이드

│       └── inference.md        # 추론 가이드

└── ... (1번 시나리오와 유사)
## **주요 모듈 및 설정** 
### **1. 백엔드 모듈**(FastAPI 기반)** 
### **backend/app/main.py - 애플리케이션 진입점** 
from fastapi import FastAPI

from fastapi.middleware.cors import CORSMiddleware

from app.api import auth, ai, user

from app.database import create\_tables

from app.config import settings

app = FastAPI(title="CR Platform API", description="AI 기사 품질 평가 API", version="1.0.0")

\# CORS 설정

app.add\_middleware(

`    `CORSMiddleware,

`    `allow\_origins=settings.ALLOWED\_ORIGINS,

`    `allow\_credentials=True,

`    `allow\_methods=["\*"],

`    `allow\_headers=["\*"],

)

\# 라우터 등록

app.include\_router(auth.router, prefix="/api/v1/auth", tags=["인증"])

app.include\_router(ai.router, prefix="/api/v1/ai", tags=["AI"])

app.include\_router(user.router, prefix="/api/v1/users", tags=["사용자"])

@app.on\_event("startup")

async def startup\_event():

`    `# 데이터베이스 테이블 생성

`    `create\_tables()

@app.get("/", tags=["상태"])

async def root():

`    `return {"status": "online", "version": "1.0.0"}
### **backend/app/api/ai.py - AI 엔드포인트** 
from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks

from typing import Optional

from app.schemas.article import ArticleInput, ArticleAnalysis

from app.services.analysis.article import ArticleService

from app.services.ai.anthropic import AnthropicService

from app.middlewares.auth import get\_current\_user

router = APIRouter()

article\_service = ArticleService()

ai\_service = AnthropicService()

@router.post("/analyze", response\_model=ArticleAnalysis)

async def analyze\_article(

`    `article: ArticleInput,

`    `background\_tasks: BackgroundTasks,

`    `current\_user = Depends(get\_current\_user)

):

`    `"""기사 텍스트 또는 URL을 분석하여 품질 점수를 반환합니다."""

`    `try:

`        `# URL 입력 시 크롤링

`        `if article.url and not article.text:

`            `article\_data = await article\_service.extract\_from\_url(article.url)

`            `article.text = article\_data.content

`            `article.title = article\_data.title

`        `# 입력 검증

`        `if not article.text:

`            `raise HTTPException(status\_code=400, detail="기사 텍스트 또는 URL이 필요합니다.")

`        `# AI 분석 수행

`        `analysis\_result = await ai\_service.analyze\_article(article.text)

`        `# 분석 결과 저장 (비동기로 처리)

`        `background\_tasks.add\_task(

`            `article\_service.save\_analysis\_result,

`            `user\_id=current\_user.id,

`            `article=article,

`            `result=analysis\_result

`        `)

`        `return analysis\_result

`    `except Exception as e:

`        `raise HTTPException(status\_code=500, detail=f"분석 중 오류 발생: {str(e)}")
### **backend/app/services/ai/anthropic.py - Anthropic Claude API 연동** 
import anthropic

from app.config import settings

from typing import Dict, Any

import logging

logger = logging.getLogger(\_\_name\_\_)

class AnthropicService:

`    `def \_\_init\_\_(self):

`        `self.client = anthropic.Anthropic(api\_key=settings.ANTHROPIC\_API\_KEY)

`        `self.model = settings.ANTHROPIC\_MODEL

`    `async def analyze\_article(self, article\_text: str) -> Dict[str, Any]:

`        `"""Anthropic Claude API를 사용하여 기사를 분석합니다."""

`        `try:

`            `# 프롬프트 구성

`            `prompt = self.\_build\_analysis\_prompt(article\_text)

`            `# Claude API 호출

`            `response = await self.client.messages.create(

`                `model=self.model,

`                `max\_tokens=4000,

`                `temperature=0.1,

`                `system="당신은 저널리즘 전문가로 기사의 품질을 객관적으로 분석합니다.",

`                `messages=[

`                    `{"role": "user", "content": prompt}

`                `]

`            `)

`            `# 응답 후처리

`            `result = self.\_parse\_response(response.content[0].text)

`            `return result

`        `except Exception as e:

`            `logger.error(f"Claude API 호출 중 오류: {str(e)}")

`            `raise ValueError(f"기사 분석 실패: {str(e)}")

`    `def \_build\_analysis\_prompt(self, article\_text: str) -> str:

`        `"""분석 프롬프트를 구성합니다."""

`        `return f"""

분석 지침: 아래 기사를 8가지 저널리즘 품질 차원에 따라 평가해주세요.

1\. 진실성과 정확성 (Truth & Accuracy)

2\. 투명성과 책임성 (Transparency & Accountability)

3\. 균형성과 공정성 (Balance & Fairness)

4\. 독립성과 자율성 (Independence & Autonomy)

5\. 인권과 프라이버시 (Human Rights & Privacy)

6\. 전문성과 심층성 (Professionalism & Depth)

7\. 언어와 표현의 윤리 (Ethics of Language)

8\. 디지털 환경의 윤리 (Digital Ethics)

다음 문제적 보도 패턴을 탐지하고 위치를 표시해주세요:

\- 무주체 피동형 표현 (예: "~로 알려졌다", "~로 전해졌다")

\- 익명 취재원 남용

\- 주관적 형용사/부사 사용

\- 인용구의 주관적 술어 사용

\- 사실과 의견 혼재

\- 맥락 정보 부족

\- 취재원 다양성 부족

\- 선정적/과장된 표현

분석 대상 기사:

{article\_text} 

응답 형식:

1\. 종합 점수: 100점 만점

2\. 차원별 점수: 각 차원별 100점 만점 평가

3\. 탐지된 문제 패턴: 각 패턴의 예시와 위치

4\. 개선 제안: 각 문제별 구체적 개선 방법

"""

`    `def \_parse\_response(self, response\_text: str) -> Dict[str, Any]:

`        `"""Claude API 응답을 파싱합니다."""

`        `# (실제 구현에서는 정규표현식이나 구조화된 파싱 로직 추가)

`        `# 간단한 예시 구현

`        `return {

`            `"overall\_score": 80, # 파싱 로직으로 실제 값 추출 필요

`            `"dimension\_scores": {

`                `"truth\_accuracy": 85,

`                `"transparency\_accountability": 75,

`                `# 나머지 차원 점수...

`            `},

`            `"patterns\_detected": [

`                `{"pattern": "무주체 피동형 표현", "examples": ["알려졌다", "전해졌다"], "locations": [{"line": 3, "text": "정부는 이번 조치가 경제에 긍정적 영향을 미칠 것으로 전망된다고 밝혔다."}]},

`                `# 기타 탐지된 패턴...

`            `],

`            `"improvements": [

`                `{"pattern": "무주체 피동형 표현", "suggestion": "정보 출처를 명확히 밝히세요. '~로 알려졌다' 대신 '~부 관계자는 ~라고 말했다'와 같이 구체적으로 작성하세요."},

`                `# 기타 개선 제안...

`            `],

`            `"raw\_analysis": response\_text

`        `}
### **2. 프론트엔드 모듈**(React + Vite)
### **frontend/src/components/analysis/UrlInput.jsx** 
import { useState } from 'react';

import { Button, Input, FormControl, FormLabel, FormErrorMessage, Box, useToast } from '@chakra-ui/react';

const UrlInput = ({ onAnalyze, isLoading }) => {

`  `const [url, setUrl] = useState('');

`  `const [error, setError] = useState('');

`  `const toast = useToast();

`  `const validateUrl = (value) => {

`    `try {

`      `new URL(value);

`      `return true;

`    `} catch (e) {

`      `return false;

`    `}

`  `};

`  `const handleSubmit = (e) => {

`    `e.preventDefault();

`    `if (!url.trim()) {

`      `setError('URL을 입력해주세요.');

`      `return;

`    `}

`    `if (!validateUrl(url)) {

`      `setError('유효한 URL 형식이 아닙니다.');

`      `return;

`    `}

`    `setError('');

`    `try {

`      `onAnalyze({ url });

`    `} catch (error) {

`      `toast({

`        `title: '분석 요청 실패',

`        `description: error.message || '기사 분석 중 오류가 발생했습니다.',

`        `status: 'error',

`        `duration: 5000,

`        `isClosable: true,

`      `});

`    `}

`  `};

`  `return (

`    `<Box as="form" onSubmit={handleSubmit} width="100%">

`      `<FormControl isInvalid={!!error}>

`        `<FormLabel>뉴스 기사 URL</FormLabel>

`        `<Input

`          `type="text"

`          `placeholder="https://example.com/news/article"

`          `value={url}

`          `onChange={(e) => setUrl(e.target.value)}

`          `disabled={isLoading}

`        `/>

`        `<FormErrorMessage>{error}</FormErrorMessage>

`      `</FormControl>

`      `<Button

`        `mt={4}

`        `colorScheme="blue"

`        `type="submit"

`        `isLoading={isLoading}

`        `loadingText="분석 중..."

`        `width="100%"

`      `>

`        `분석하기

`      `</Button>

`    `</Box>

`  `);

};

export default UrlInput;
### **frontend/src/services/api.js** 
import axios from 'axios';

const API\_BASE\_URL = import.meta.env.VITE\_API\_URL || 'http://localhost:8000/api/v1';

// API 클라이언트 인스턴스 생성

const apiClient = axios.create({

`  `baseURL: API\_BASE\_URL,

`  `headers: {

`    `'Content-Type': 'application/json',

`  `},

`  `withCredentials: true,

});

// 요청 인터셉터 - 토큰 추가

apiClient.interceptors.request.use(

`  `(config) => {

`    `const token = localStorage.getItem('token');

`    `if (token) {

`      `config.headers.Authorization = `Bearer ${token}`;

`    `}

`    `return config;

`  `},

`  `(error) => Promise.reject(error)

);

// 응답 인터셉터 - 에러 처리

apiClient.interceptors.response.use(

`  `(response) => response,

`  `(error) => {

`    `// 인증 오류 처리

`    `if (error.response && error.response.status === 401) {

`      `localStorage.removeItem('token');

`      `window.location.href = '/login';

`    `}

`    `return Promise.reject(error);

`  `}

);

// API 함수들

export const authAPI = {

`  `login: (credentials) => apiClient.post('/auth/login', credentials),

`  `register: (userData) => apiClient.post('/auth/register', userData),

`  `logout: () => apiClient.post('/auth/logout'),

`  `getProfile: () => apiClient.get('/auth/profile'),

};

export const analysisAPI = {

`  `analyzeArticle: (data) => apiClient.post('/ai/analyze', data),

`  `getHistory: (page = 1, limit = 10) =>

`    `apiClient.get('/ai/history', { params: { page, limit } }),

`  `getAnalysisById: (id) => apiClient.get(`/ai/analysis/${id}`),

};

export const userAPI = {

`  `updateProfile: (data) => apiClient.put('/users/profile', data),

`  `changePassword: (data) => apiClient.put('/users/password', data),

};

export default apiClient;
### **3. ML 모듈 구성**(오픈소스 LLM 파인튜닝 시)
### **ml/training/scripts/fine\_tune.py** 
import os

import argparse

import torch

from transformers import (

`    `AutoModelForCausalLM,

`    `AutoTokenizer,

`    `TrainingArguments,

`    `Trainer,

`    `DataCollatorForLanguageModeling

)

from datasets import load\_dataset

from peft import LoraConfig, get\_peft\_model, TaskType

def parse\_args():

`    `parser = argparse.ArgumentParser(description="기사 품질 평가 모델 파인튜닝")

`    `parser.add\_argument("--base\_model", type=str, default="meta-llama/Llama-2-7b-hf", help="기본 모델 이름")

`    `parser.add\_argument("--data\_path", type=str, required=True, help="훈련 데이터 경로")

`    `parser.add\_argument("--output\_dir", type=str, default="./output", help="모델 저장 경로")

`    `parser.add\_argument("--lora\_r", type=int, default=8, help="LoRA 랭크")

`    `parser.add\_argument("--lora\_alpha", type=int, default=16, help="LoRA 알파")

`    `parser.add\_argument("--learning\_rate", type=float, default=3e-4, help="학습률")

`    `parser.add\_argument("--batch\_size", type=int, default=4, help="배치 크기")

`    `parser.add\_argument("--epochs", type=int, default=3, help="에폭 수")

`    `return parser.parse\_args()

def main():

`    `args = parse\_args()

`    `# 모델 및 토크나이저 로드

`    `model = AutoModelForCausalLM.from\_pretrained(

`        `args.base\_model,

`        `torch\_dtype=torch.bfloat16,

`        `device\_map="auto",

`    `)

`    `tokenizer = AutoTokenizer.from\_pretrained(args.base\_model)

`    `tokenizer.pad\_token = tokenizer.eos\_token

`    `# PEFT/LoRA 설정

`    `peft\_config = LoraConfig(

`        `task\_type=TaskType.CAUSAL\_LM,

`        `inference\_mode=False,

`        `r=args.lora\_r,

`        `lora\_alpha=args.lora\_alpha,

`        `target\_modules=["q\_proj", "v\_proj", "k\_proj", "o\_proj"]

`    `)

`    `model = get\_peft\_model(model, peft\_config)

`    `# 데이터셋 로드

`    `dataset = load\_dataset("json", data\_files=args.data\_path)

`    `# 데이터 전처리 함수

`    `def preprocess\_function(examples):

`        `# 입력 텍스트 구성

`        `inputs = []

`        `targets = []

`        `for article, analysis in zip(examples["article"], examples["analysis"]):

`            `prompt = f"""

분석 지침: 아래 기사를 8가지 저널리즘 품질 차원에 따라 평가해주세요.

1\. 진실성과 정확성 (Truth & Accuracy)

2\. 투명성과 책임성 (Transparency & Accountability)

3\. 균형성과 공정성 (Balance & Fairness)

4\. 독립성과 자율성 (Independence & Autonomy)

5\. 인권과 프라이버시 (Human Rights & Privacy)

6\. 전문성과 심층성 (Professionalism & Depth)

7\. 언어와 표현의 윤리 (Ethics of Language)

8\. 디지털 환경의 윤리 (Digital Ethics)

분석 대상 기사:

{article}

응답:

"""

`            `inputs.append(prompt)

`            `targets.append(analysis)

`        `# 토큰화

`        `model\_inputs = tokenizer(inputs, padding="max\_length", truncation=True, max\_length=1024)

`        `labels = tokenizer(targets, padding="max\_length", truncation=True, max\_length=1024)

`        `# 입력과 레이블 모두 동일한 길이를 가져야 함

`        `model\_inputs["labels"] = labels["input\_ids"]

`        `return model\_inputs

`    `# 데이터 전처리

`    `tokenized\_dataset = dataset.map(

`        `preprocess\_function,

`        `batched=True,

`        `remove\_columns=dataset["train"].column\_names

`    `)

`    `# 훈련 인자 설정

`    `training\_args = TrainingArguments(

`        `output\_dir=args.output\_dir,

`        `per\_device\_train\_batch\_size=args.batch\_size,

`        `learning\_rate=args.learning\_rate,

`        `num\_train\_epochs=args.epochs,

`        `weight\_decay=0.01,

`        `logging\_dir=f"{args.output\_dir}/logs",

`        `logging\_steps=10,

`        `save\_strategy="epoch",

`        `fp16=True,

`    `)

`    `# 데이터 콜레이터 설정

`    `data\_collator = DataCollatorForLanguageModeling(

`        `tokenizer=tokenizer,

`        `mlm=False

`    `)

`    `# 트레이너 초기화

`    `trainer = Trainer(

`        `model=model,

`        `args=training\_args,

`        `train\_dataset=tokenized\_dataset["train"],

`        `eval\_dataset=tokenized\_dataset.get("validation"),

`        `data\_collator=data\_collator,

`    `)

`    `# 모델 훈련

`    `trainer.train()

`    `# 모델 저장

`    `model.save\_pretrained(f"{args.output\_dir}/final\_model")

`    `tokenizer.save\_pretrained(f"{args.output\_dir}/final\_model")

`    `print(f"모델이 {args.output\_dir}/final\_model에 저장되었습니다.")

if \_\_name\_\_ == "\_\_main\_\_":

`    `main()
### **ml/inference/inference.py** 
import os

import json

import torch

from transformers import AutoModelForCausalLM, AutoTokenizer

from peft import PeftModel, PeftConfig

\# 모델 및 토크나이저 초기화 (한 번만 로드)

def model\_fn(model\_dir):

`    `"""SageMaker 엔드포인트에서 모델 로드"""

`    `# PEFT 설정 로드

`    `config = PeftConfig.from\_pretrained(model\_dir)

`    `# 기본 모델 로드

`    `model = AutoModelForCausalLM.from\_pretrained(

`        `config.base\_model\_name\_or\_path,

`        `torch\_dtype=torch.bfloat16,

`        `device\_map="auto"

`    `)

`    `# PEFT 모델 로드

`    `model = PeftModel.from\_pretrained(model, model\_dir)

`    `# 토크나이저 로드

`    `tokenizer = AutoTokenizer.from\_pretrained(config.base\_model\_name\_or\_path)

`    `tokenizer.pad\_token = tokenizer.eos\_token

`    `return {"model": model, "tokenizer": tokenizer}

\# 데이터 전처리

def input\_fn(request\_body, request\_content\_type):

`    `"""요청 데이터 전처리"""

`    `if request\_content\_type == "application/json":

`        `data = json.loads(request\_body)

`        `return data

`    `else:

`        `raise ValueError(f"지원되지 않는 콘텐츠 타입: {request\_content\_type}")

\# 예측 수행

def predict\_fn(input\_data, model\_data):

`    `"""모델 추론 실행"""

`    `model = model\_data["model"]

`    `tokenizer = model\_data["tokenizer"]

`    `# 프롬프트 구성

`    `article\_text = input\_data.get("article", "")

`    `prompt = f"""

분석 지침: 아래 기사를 8가지 저널리즘 품질 차원에 따라 평가해주세요.

1\. 진실성과 정확성 (Truth & Accuracy)

2\. 투명성과 책임성 (Transparency & Accountability)

3\. 균형성과 공정성 (Balance & Fairness)

4\. 독립성과 자율성 (Independence & Autonomy)

5\. 인권과 프라이버시 (Human Rights & Privacy)

6\. 전문성과 심층성 (Professionalism & Depth)

7\. 언어와 표현의 윤리 (Ethics of Language)

8\. 디지털 환경의 윤리 (Digital Ethics)

다음 문제적 보도 패턴을 탐지하고 위치를 표시해주세요:

\- 무주체 피동형 표현 (예: "~로 알려졌다", "~로 전해졌다")

\- 익명 취재원 남용

\- 주관적 형용사/부사 사용

\- 인용구의 주관적 술어 사용

\- 사실과 의견 혼재

\- 맥락 정보 부족

\- 취재원 다양성 부족

\- 선정적/과장된 표현

분석 대상 기사:

{article\_text} 

응답 형식:

1\. 종합 점수: 100점 만점

2\. 차원별 점수: 각 차원별 100점 만점 평가

3\. 탐지된 문제 패턴: 각 패턴의 예시와 위치

4\. 개선 제안: 각 문제별 구체적 개선 방법

"""

`    `# 토큰화 및 추론

`    `inputs = tokenizer(prompt, return\_tensors="pt").to(model.device)

`    `with torch.no\_grad():

`        `outputs = model.generate(

`            `inputs.input\_ids,

`            `max\_new\_tokens=2048,

`            `do\_sample=True,

`            `temperature=0.7,

`            `top\_p=0.9,

`            `pad\_token\_id=tokenizer.eos\_token\_id

`        `)

`    `response = tokenizer.decode(outputs[0], skip\_special\_tokens=True)

`    `# 프롬프트 부분 제거 (응답만 추출)

`    `response = response.split("응답 형식:")[1] if "응답 형식:" in response else response

`    `return response

\# 출력 포맷팅

def output\_fn(prediction, response\_content\_type):

`    `"""응답 데이터 후처리"""

`    `if response\_content\_type == "application/json":

`        `# 구조화된 응답 생성 시도

`        `try:

`            `# 텍스트 분석

`            `lines = prediction.strip().split('\n')

`            `# 종합 점수 추출

`            `overall\_score\_line = next((line for line in lines if "종합 점수" in line), "")

`            `overall\_score = int(overall\_score\_line.split(":")[1].strip().split('/')[0]) if overall\_score\_line else 0

`            `# 차원별 점수 및 문제 패턴 추출 (간단한 구현)

`            `dimension\_scores = {}

`            `patterns\_detected = []

`            `improvements = []

`            `# 응답 구조화

`            `structured\_response = {

`                `"overall\_score": overall\_score,

`                `"dimension\_scores": dimension\_scores,

`                `"patterns\_detected": patterns\_detected,

`                `"improvements": improvements,

`                `"raw\_analysis": prediction

`            `}

`            `return json.dumps(structured\_response)

`        `except Exception as e:

`            `# 구조화 실패 시 원본 텍스트 반환

`            `return json.dumps({"raw\_analysis": prediction, "error": str(e)})

`    `else:

`        `return prediction
### **4. 백엔드와 ML 서비스 간 연동**(오픈소스 LLM 시)
### **backend/app/services/ai/model\_service.py** 
import httpx

import json

import logging

from typing import Dict, Any

from app.config import settings

logger = logging.getLogger(\_\_name\_\_)

class ModelService:

`    `"""자체 파인튜닝된 LLM 호출 서비스"""

`    `def \_\_init\_\_(self):

`        `self.model\_endpoint = settings.MODEL\_ENDPOINT\_URL

`        `self.timeout = httpx.Timeout(30.0, connect=10.0)

`    `async def analyze\_article(self, article\_text: str) -> Dict[str, Any]:

`        `"""파인튜닝된 모델을 사용하여 기사를 분석합니다."""

`        `try:

`            `# 모델 서비스 호출

`            `async with httpx.AsyncClient(timeout=self.timeout) as client:

`                `response = await client.post(

`                    `self.model\_endpoint,

`                    `json={"article": article\_text},

`                    `headers={"Content-Type": "application/json"}

`                `)

`                `if response.status\_code != 200:

`                    `logger.error(f"모델 서비스 오류: {response.status\_code}, {response.text}")

`                    `raise ValueError(f"모델 서비스 응답 오류: {response.status\_code}")

`                `result = response.json()

`                `# 응답 처리 - 구조화된 형태로 변환

`                `processed\_result = self.\_process\_result(result)

`                `return processed\_result

`        `except httpx.RequestError as e:

`            `logger.error(f"모델 서비스 요청 오류: {str(e)}")

`            `raise ValueError(f"모델 서비스 연결 오류: {str(e)}")

`        `except Exception as e:

`            `logger.error(f"기사 분석 중 오류: {str(e)}")

`            `raise ValueError(f"기사 분석 실패: {str(e)}")

`    `def \_process\_result(self, raw\_result: Dict[str, Any]) -> Dict[str, Any]:

`        `"""모델 응답을 애플리케이션 형식에 맞게 처리합니다."""

`        `# 원본 응답 구조에 따라 필요한 처리 수행

`        `# 여기서는 예시로 간단한 매핑만 수행

`        `return {

`            `"overall\_score": raw\_result.get("overall\_score", 0),

`            `"dimension\_scores": raw\_result.get("dimension\_scores", {}),

`            `"patterns\_detected": raw\_result.get("patterns\_detected", []),

`            `"improvements": raw\_result.get("improvements", []),

`            `"raw\_analysis": raw\_result.get("raw\_analysis", "")

`        `}
### **backend/app/services/ai/sagemaker.py** 
import boto3

import json

import logging

from typing import Dict, Any

from app.config import settings

logger = logging.getLogger(\_\_name\_\_)

class SageMakerService:

`    `"""AWS SageMaker를 통한 모델 호출 서비스"""

`    `def \_\_init\_\_(self):

`        `# AWS 인증 설정

`        `self.session = boto3.Session(

`            `aws\_access\_key\_id=settings.AWS\_ACCESS\_KEY\_ID,

`            `aws\_secret\_access\_key=settings.AWS\_SECRET\_ACCESS\_KEY,

`            `region\_name=settings.AWS\_REGION

`        `)

`        `self.sagemaker\_runtime = self.session.client('sagemaker-runtime')

`        `self.endpoint\_name = settings.SAGEMAKER\_ENDPOINT\_NAME

`    `async def analyze\_article(self, article\_text: str) -> Dict[str, Any]:

`        `"""SageMaker 엔드포인트를 호출하여 기사를 분석합니다."""

`        `try:

`            `# SageMaker 엔드포인트 호출

`            `response = self.sagemaker\_runtime.invoke\_endpoint(

`                `EndpointName=self.endpoint\_name,

`                `ContentType='application/json',

`                `Body=json.dumps({"article": article\_text})

`            `)

`            `# 응답 처리

`            `response\_body = json.loads(response['Body'].read().decode())

`            `# 구조화된 응답 생성

`            `result = self.\_process\_response(response\_body)

`            `return result

`        `except self.sagemaker\_runtime.exceptions.ModelError as e:

`            `logger.error(f"SageMaker 모델 오류: {str(e)}")

`            `raise ValueError(f"모델 추론 실패: {str(e)}")

`        `except Exception as e:

`            `logger.error(f"SageMaker 호출 중 오류: {str(e)}")

`            `raise ValueError(f"기사 분석 실패: {str(e)}")

`    `def \_process\_response(self, response\_body: Dict[str, Any]) -> Dict[str, Any]:

`        `"""SageMaker 응답을 애플리케이션 형식에 맞게 처리합니다."""

`        `# 필요에 따라 응답 구조 변환

`        `return {

`            `"overall\_score": response\_body.get("overall\_score", 0),

`            `"dimension\_scores": response\_body.get("dimension\_scores", {}),

`            `"patterns\_detected": response\_body.get("patterns\_detected", []),

`            `"improvements": response\_body.get("improvements", []),

`            `"raw\_analysis": response\_body.get("raw\_analysis", "")

`        `}
## **시스템 간 상호작용** 
### **1. 기본 시스템 흐름도**
`                           `+-------------------+

`                           `|                   |

`                           `|   사용자 (브라우저) |

`                           `|                   |

`                           `+--------+----------+

`                                    `|

`                                    `| HTTP 요청/응답

`                                    `|

`                 `+------------------v-------------------+

`                 `|                                      |

`                 `|            Nginx (웹 서버)            |

`                 `|                                      |

`                 `+--------------+---------------------+

`                                `|

`                                `| 프록시

`                                `|

`       `+------------------------|-------------------------+

`       `|                        |                         |

+------v-------+      +---------v---------+     +--------v--------+

|	|      |                   |     |                 |

| 프론트엔드 서버  |      |   백엔드 API 서버   |     |   데이터베이스   |

| (React/Nginx) |      |   (FastAPI/Flask) |     |  (PostgreSQL)   |

|	|      |                   |     |                 |

+------+-------+      +---------+---------+     +-----------------+

`       `|                        |

`       `| 정적 파일 제공           | API 호출/응답

`       `|                        |

`       `|                        v

`       `|        +--------------------------------+

`       `|        |                                |

`       `|        |         AI 서비스 계층           |

`       `|        |                                |

`       `|        +-------------+------------------+

`       `|                      |

`       `|                      | 모델 서빙

`       `|                      |

`       `|        +-------------v------------------+

`       `|        |                                |

`       `|        |   상용 API 또는 자체 LLM 모델     |

`       `|        |                                |

`       `|        +--------------------------------+

`       `|

`       `v

`  `+----+-----+

`  `|          |

`  `|  CDN     |

`  `| (선택적)  |

`  `|          |

`  `+----------+
### **2. 핵심 컴포넌트 간 상호작용**
1. **사용자 요청 흐름** : 
   1. 사용자가 브라우저에서 기사 URL을 입력하거나 텍스트를 붙여넣기 
   1. 프론트엔드 UrlInput.jsx 또는 TextInput.jsx 컴포넌트가 입력 검증 
   1. API 클라이언트 api.js 의 analyzeArticle 함수를 통해 백엔드 API 호출 
   1. 백엔드 ai.py 라우터가 요청을 수신하고 적절한 서비스 호출 
   1. 상용 API 사용 시: AnthropicService 가 Claude API 호출 
   1. 자체 LLM 사용 시: ModelService 또는 SageMakerService 가 모델 엔드포인트 호출 
   1. 백엔드가 분석 결과를 처리하여 프론트엔드에 반환 
   1. 프론트엔드가 ResultSummary.jsx 및 ArticleHighlight.jsx 등으로 결과 시각화 
2. **데이터 흐름** : 
   1. 기사 데이터: 사용자 입력 → 프론트엔드 → 백엔드 → AI 서비스 → 모델 
   1. 분석 결과: 모델 → AI 서비스 → 백엔드 → 프론트엔드 → 사용자 화면 
   1. 데이터베이스 저장: 백엔드가 분석 결과를 DB에 저장 (사용자 기록 관리) 
3. **서비스 간 의존성** : 
   1. backend/app/api/ai.py → backend/app/services/analysis/article.py (기사 처리) 
   1. backend/app/services/analysis/article.py → backend/app/services/ai/\* (AI 서비스) 
   1. backend/app/services/ai/anthropic.py → Anthropic API (상용 API 시) 
   1. backend/app/services/ai/model\_service.py → 자체 모델 엔드포인트 (자체 LLM 시) 
   1. backend/app/services/ai/sagemaker.py → AWS SageMaker 엔드포인트 (자체 LLM+AWS 시) 
## **단계적 구현 전략** 
### **1. MVP(최소 기능 제품) 구축 단계**(1-2개월)
1. **기초 설정 및 기본 기능 구현** : 
   1. 백엔드 프레임워크 설정 (FastAPI/Flask) 
   1. 기본 데이터베이스 스키마 설계 및 구현 
   1. 프론트엔드 기본 구조 구현 (React 컴포넌트) 
   1. Claude API 연동 (가장 빠른 AI 통합 방식) 
   1. 기사 URL 크롤링 및 텍스트 추출 기능 
2. **핵심 기능 구현** : 
   1. 기사 분석 API 엔드포인트 
   1. 분석 결과 시각화 (점수, 문제점 하이라이트) 
   1. 사용자 인증 및 분석 이력 관리 
3. **로컬 개발 환경 설정** : 
   1. Docker 기반 개발 환경 구성 
   1. 개발용 데이터베이스 설정 
   1. 기본 CI/CD 파이프라인 구축 
### **2. 기능 확장 단계**(2-3개월)
1. **사용자 경험 개선** : 
   1. 분석 결과 시각화 개선 (차트, 인터랙티브 요소) 
   1. 분석 결과 공유 기능 
   1. 사용자 설정 및 커스터마이징 옵션 
2. **AI 기능 향상** : 
   1. 모델 프롬프트 최적화 
   1. 다양한 기사 유형에 맞는 분석 템플릿 개발 
   1. 분석 정확도 개선을 위한 피드백 시스템 구축 
3. **데이터 수집 및 관리** : 
   1. 분석 결과 데이터베이스 설계 개선 
   1. 사용자 피드백 수집 시스템 구축 
   1. 학습용 데이터셋 구축 시작 
### **3. 독자적 모델 개발 단계**(3-6개월)
1. **데이터셋 구축** : 
   1. 충분한 기사-분석 쌍 데이터 수집 
   1. 데이터 정제 및 레이블링 
   1. 훈련/검증/테스트 데이터셋 분할 
2. **모델 파인튜닝** : 
   1. 오픈소스 LLM(Llama, Mistral 등) 선택 
   1. LoRA 등 파라미터 효율적 파인튜닝 적용 
   1. 성능 평가 및 모델 최적화 
3. **추론 인프라 구축** : 
   1. 고성능 추론 서버 설정 
   1. 모델 압축 및 최적화 
   1. API 호환성 유지 
### **4. 프로덕션 및 확장 단계**(6개월 이후)
1. **하이브리드 전략 구현** : 
   1. 상용 API와 자체 모델을 상황에 맞게 선택적으로 사용 
   1. 복잡한 분석은 상용 API, 기본 분석은 자체 모델로 처리 
2. **인프라 확장** : 
   1. 부하 분산 설정 
   1. 서버리스 아키텍처 도입 
   1. 컨테이너 오케스트레이션 (Kubernetes 등) 
3. **커뮤니티 기능 구축** : 
   1. 사용자 간 분석 결과 공유 및 토론 
   1. Discord 통합 및 커뮤니티 관리 
   1. 집단지성 기반 모델 개선 
## **기술 선택 가이드라인** 
### **1. 프로젝트 예산 및 일정에 따른 접근법**

|예산/일정 |권장 접근법 |근거 |
| :- | :- | :- |
|**제한적 예산 & 빠른 출시** |상용 API |개발 기간 단축, 초기 자본 투자 최소화 |
|**충분한 예산 & 장기 계획** |오픈소스 LLM |장기적 비용 효율성, 완전한 제어 가능 |
|**중간 예산 & 단계적 접근** |하이브리드 접근법 |MVP는 상용 API로 시작하고 점진적으로 자체 모델 개발 |
### **2. 기술적 역량에 따른 선택**

|팀 역량 |권장 접근법 |필요 기술 |
| :- | :- | :- |
|**웹 개발 중심** |상용 API |웹 프레임워크, API 연동 |
|**ML/AI 전문가 포함** |오픈소스 LLM |PyTorch, 모델 파인튜닝, 인프라 관리 |
|**풀스택 팀** |하이브리드 접근법 |웹 개발 + 기본적인 ML 지식 |
### **3. 데이터 프라이버시 요구사항**

|프라이버시 요구 |권장 접근법 |구현 방안 |
| :- | :- | :- |
|**높은 프라이버시** |오픈소스 LLM |자체 인프라에서 모든 데이터 처리 |
|**일반적 수준** |상용 API |민감 정보 필터링 후 API 전송 |
|**맞춤형 제어** |하이브리드 접근법 |민감 데이터는 자체 모델, 일반 데이터는 상용 API |
### **4. 확장성 요구사항**

|확장성 요구 |권장 접근법 |인프라 고려사항 |
| :- | :- | :- |
|**소규모 사용자** |상용 API |서버리스 아키텍처 (AWS Lambda 등) |
|**대규모 사용자** |오픈소스 LLM |컨테이너 오케스트레이션 (Kubernetes) |
|**가변적 트래픽** |하이브리드 접근법 |오토스케일링 + 부하 분산 |
## **배포 및 인프라 설정** 
### **1. Docker 컨테이너 구성**
### **docker-compose.yml (개발 환경)** 
version: '3.8'

services:

`  `frontend:

`    `build:

`      `context: ./frontend

`      `dockerfile: ../docker/frontend/Dockerfile

`    `ports:

`      `- "3000:3000"

`    `volumes:

`      `- ./frontend:/app

`      `- /app/node\_modules

`    `environment:

`      `- VITE\_API\_URL=http://localhost:8000/api/v1

`    `depends\_on:

`      `- backend

`    `networks:

`      `- cr-network

`  `backend:

`    `build:

`      `context: ./backend

`      `dockerfile: ../docker/backend/Dockerfile

`    `ports:

`      `- "8000:8000"

`    `volumes:

`      `- ./backend:/app

`    `environment:

`      `- DATABASE\_URL=postgresql://postgres:postgres@db:5432/cr\_db

`      `- ANTHROPIC\_API\_KEY=${ANTHROPIC\_API\_KEY}

`      `- ANTHROPIC\_MODEL=claude-3-opus-20240229

`      `- JWT\_SECRET=dev\_secret\_key

`      `- ENVIRONMENT=development

`      `- ALLOWED\_ORIGINS=http://localhost:3000

`    `depends\_on:

`      `- db

`    `networks:

`      `- cr-network

`  `db:

`    `image: postgres:14

`    `ports:

`      `- "5432:5432"

`    `environment:

`      `- POSTGRES\_USER=postgres

`      `- POSTGRES\_PASSWORD=postgres

`      `- POSTGRES\_DB=cr\_db

`    `volumes:

`      `- postgres\_data:/var/lib/postgresql/data

`    `networks:

`      `- cr-network

networks:

`  `cr-network:

`    `driver: bridge

volumes:

`  `postgres\_data:
### **docker-compose.prod.yml (프로덕션 환경)** 
version: '3.8'

services:

`  `frontend:

`    `build:

`      `context: ./frontend

`      `dockerfile: ../docker/frontend/Dockerfile

`      `args:

`        `- NODE\_ENV=production

`    `ports:

`      `- "80:80"

`      `- "443:443"

`    `environment:

`      `- VITE\_API\_URL=/api/v1

`    `networks:

`      `- cr-network

`    `restart: always

`  `backend:

`    `build:

`      `context: ./backend

`      `dockerfile: ../docker/backend/Dockerfile

`    `expose:

`      `- "8000"

`    `environment:

`      `- DATABASE\_URL=${DATABASE\_URL}

`      `- ANTHROPIC\_API\_KEY=${ANTHROPIC\_API\_KEY}

`      `- ANTHROPIC\_MODEL=${ANTHROPIC\_MODEL}

`      `- JWT\_SECRET=${JWT\_SECRET}

`      `- ENVIRONMENT=production

`      `- ALLOWED\_ORIGINS=${ALLOWED\_ORIGINS}

`    `networks:

`      `- cr-network

`    `restart: always

`    `depends\_on:

`      `- db

`  `db:

`    `image: postgres:14

`    `volumes:

`      `- postgres\_data:/var/lib/postgresql/data

`    `environment:

`      `- POSTGRES\_USER=${POSTGRES\_USER}

`      `- POSTGRES\_PASSWORD=${POSTGRES\_PASSWORD}

`      `- POSTGRES\_DB=${POSTGRES\_DB}

`    `networks:

`      `- cr-network

`    `restart: always

`  `nginx:

`    `image: nginx:alpine

`    `ports:

`      `- "80:80"

`      `- "443:443"

`    `volumes:

`      `- ./docker/nginx/nginx.conf:/etc/nginx/conf.d/default.conf

`      `- ./docker/nginx/ssl:/etc/nginx/ssl

`    `depends\_on:

`      `- frontend

`      `- backend

`    `networks:

`      `- cr-network

`    `restart: always

networks:

`  `cr-network:

`    `driver: bridge

volumes:

`  `postgres\_data:
### **2. AWS 배포 구성**(Terraform)
### **infrastructure/terraform/main.tf** 
provider "aws" {

`  `region = var.aws\_region

}

\# VPC 설정

module "vpc" {

`  `source = "terraform-aws-modules/vpc/aws"

`  `name   = "cr-platform-vpc"

`  `cidr   = "10.0.0.0/16"

`  `azs             = ["${var.aws\_region}a", "${var.aws\_region}b"]

`  `private\_subnets = ["10.0.1.0/24", "10.0.2.0/24"]

`  `public\_subnets  = ["10.0.101.0/24", "10.0.102.0/24"]

`  `enable\_nat\_gateway = true

`  `single\_nat\_gateway = true

`  `tags = {

`    `Project     = "CR Platform"

`    `Environment = var.environment

`  `}

}

\# ECS 클러스터

resource "aws\_ecs\_cluster" "cr\_cluster" {

`  `name = "cr-platform-cluster"

`  `setting {

`    `name  = "containerInsights"

`    `value = "enabled"

`  `}

`  `tags = {

`    `Project     = "CR Platform"

`    `Environment = var.environment

`  `}

}

\# RDS 인스턴스

resource "aws\_db\_instance" "postgres" {

`  `allocated\_storage    = 20

`  `storage\_type         = "gp2"

`  `engine               = "postgres"

`  `engine\_version       = "14"

`  `instance\_class       = "db.t3.micro"

`  `name                 = "cr\_db"

`  `username             = var.db\_username

`  `password             = var.db\_password

`  `parameter\_group\_name = "default.postgres14"

`  `skip\_final\_snapshot  = true

`  `vpc\_security\_group\_ids = [aws\_security\_group.rds\_sg.id]

`  `db\_subnet\_group\_name   = aws\_db\_subnet\_group.cr\_db\_subnet\_group.name

`  `tags = {

`    `Project     = "CR Platform"

`    `Environment = var.environment

`  `}

}

\# 보안 그룹

resource "aws\_security\_group" "ecs\_sg" {

`  `name        = "cr-ecs-sg"

`  `description = "ECS security group"

`  `vpc\_id      = module.vpc.vpc\_id

`  `ingress {

`    `from\_port   = 80

`    `to\_port     = 80

`    `protocol    = "tcp"

`    `cidr\_blocks = ["0.0.0.0/0"]

`  `}

`  `ingress {

`    `from\_port   = 8000

`    `to\_port     = 8000

`    `protocol    = "tcp"

`    `cidr\_blocks = ["0.0.0.0/0"]

`  `}

`  `egress {

`    `from\_port   = 0

`    `to\_port     = 0

`    `protocol    = "-1"

`    `cidr\_blocks = ["0.0.0.0/0"]

`  `}

`  `tags = {

`    `Project     = "CR Platform"

`    `Environment = var.environment

`  `}

}

resource "aws\_security\_group" "rds\_sg" {

`  `name        = "cr-rds-sg"

`  `description = "RDS security group"

`  `vpc\_id      = module.vpc.vpc\_id

`  `ingress {

`    `from\_port       = 5432

`    `to\_port         = 5432

`    `protocol        = "tcp"

`    `security\_groups = [aws\_security\_group.ecs\_sg.id]

`  `}

`  `egress {

`    `from\_port   = 0

`    `to\_port     = 0

`    `protocol    = "-1"

`    `cidr\_blocks = ["0.0.0.0/0"]

`  `}

`  `tags = {

`    `Project     = "CR Platform"

`    `Environment = var.environment

`  `}

}

\# DB 서브넷 그룹

resource "aws\_db\_subnet\_group" "cr\_db\_subnet\_group" {

`  `name       = "cr-db-subnet-group"

`  `subnet\_ids = module.vpc.private\_subnets

`  `tags = {

`    `Project     = "CR Platform"

`    `Environment = var.environment

`  `}

}

\# ECR 저장소

resource "aws\_ecr\_repository" "backend\_repo" {

`  `name                 = "cr-platform-backend"

`  `image\_tag\_mutability = "MUTABLE"

`  `image\_scanning\_configuration {

`    `scan\_on\_push = true

`  `}

`  `tags = {

`    `Project     = "CR Platform"

`    `Environment = var.environment

`  `}

}

resource "aws\_ecr\_repository" "frontend\_repo" {

`  `name                 = "cr-platform-frontend"

`  `image\_tag\_mutability = "MUTABLE"

`  `image\_scanning\_configuration {

`    `scan\_on\_push = true

`  `}

`  `tags = {

`    `Project     = "CR Platform"

`    `Environment = var.environment

`  `}

}

\# 오픈소스 LLM을 사용하는 경우 추가 리소스

resource "aws\_ecr\_repository" "ml\_repo" {

`  `count                = var.use\_own\_model ? 1 : 0

`  `name                 = "cr-platform-ml"

`  `image\_tag\_mutability = "MUTABLE"

`  `image\_scanning\_configuration {

`    `scan\_on\_push = true

`  `}

`  `tags = {

`    `Project     = "CR Platform"

`    `Environment = var.environment

`  `}

}

\# SageMaker 모델 배포 (자체 LLM 사용 시)

module "sagemaker" {

`  `count  = var.use\_own\_model ? 1 : 0

`  `source = "./modules/ml"

`  `model\_name     = "cr-model"

`  `image\_uri      = "${aws\_ecr\_repository.ml\_repo[0].repository\_url}:latest"

`  `instance\_type  = "ml.g4dn.xlarge"

`  `instance\_count = 1

`  `tags = {

`    `Project     = "CR Platform"

`    `Environment = var.environment

`  `}

}
### **3. SageMaker 모델 배포**(오픈소스 LLM 시)
### **ml/deployment/aws/sagemaker/deploy.py** 
import boto3

import argparse

import json

import os

from datetime import datetime

def parse\_args():

`    `parser = argparse.ArgumentParser(description="SageMaker 모델 배포")

`    `parser.add\_argument("--model-name", type=str, required=True, help="모델 이름")

`    `parser.add\_argument("--model-data", type=str, required=True, help="모델 데이터 S3 URI")

`    `parser.add\_argument("--role-arn", type=str, required=True, help="SageMaker IAM 역할 ARN")

`    `parser.add\_argument("--image-uri", type=str, required=True, help="ECR 이미지 URI")

`    `parser.add\_argument("--instance-type", type=str, default="ml.g4dn.xlarge", help="인스턴스 타입")

`    `parser.add\_argument("--instance-count", type=int, default=1, help="인스턴스 수")

`    `return parser.parse\_args()

def deploy\_model\_to\_sagemaker(args):

`    `# SageMaker 클라이언트 생성

`    `sagemaker\_client = boto3.client('sagemaker')

`    `# 현재 시간을 기반으로 버전 생성

`    `timestamp = datetime.now().strftime("%Y%m%d%H%M%S")

`    `model\_name = f"{args.model\_name}-{timestamp}"

`    `# 모델 생성

`    `print(f"모델 생성 중: {model\_name}")

`    `model\_response = sagemaker\_client.create\_model(

`        `ModelName=model\_name,

`        `PrimaryContainer={

`            `'Image': args.image\_uri,

`            `'ModelDataUrl': args.model\_data,

`            `'Environment': {

`                `'SAGEMAKER\_CONTAINER\_LOG\_LEVEL': '20',

`                `'SAGEMAKER\_REGION': boto3.session.Session().region\_name

`            `}

`        `},

`        `ExecutionRoleArn=args.role\_arn,

`        `Tags=[

`            `{

`                `'Key': 'Project',

`                `'Value': 'CR Platform'

`            `}

`        `]

`    `)

`    `# 엔드포인트 설정 생성

`    `print(f"엔드포인트 설정 생성 중")

`    `endpoint\_config\_name = f"{model\_name}-config"

`    `endpoint\_config\_response = sagemaker\_client.create\_endpoint\_config(

`        `EndpointConfigName=endpoint\_config\_name,

`        `ProductionVariants=[

`            `{

`                `'VariantName': 'AllTraffic',

`                `'ModelName': model\_name,

`                `'InstanceType': args.instance\_type,

`                `'InitialInstanceCount': args.instance\_count,

`                `'InitialVariantWeight': 1.0

`            `}

`        `],

`        `Tags=[

`            `{

`                `'Key': 'Project',

`                `'Value': 'CR Platform'

`            `}

`        `]

`    `)

`    `# 엔드포인트 이름

`    `endpoint\_name = f"{args.model\_name}-endpoint"

`    `# 기존 엔드포인트 확인

`    `try:

`        `sagemaker\_client.describe\_endpoint(EndpointName=endpoint\_name)

`        `# 기존 엔드포인트가 있으면 업데이트

`        `print(f"기존 엔드포인트 업데이트 중: {endpoint\_name}")

`        `endpoint\_response = sagemaker\_client.update\_endpoint(

`            `EndpointName=endpoint\_name,

`            `EndpointConfigName=endpoint\_config\_name

`        `)

`    `except sagemaker\_client.exceptions.ClientError:

`        `# 기존 엔드포인트가 없으면 새로 생성

`        `print(f"새 엔드포인트 생성 중: {endpoint\_name}")

`        `endpoint\_response = sagemaker\_client.create\_endpoint(

`            `EndpointName=endpoint\_name,

`            `EndpointConfigName=endpoint\_config\_name,

`            `Tags=[

`                `{

`                    `'Key': 'Project',

`                    `'Value': 'CR Platform'

`                `}

`            `]

`        `)

`    `print(f"엔드포인트 배포 시작: {endpoint\_name}")

`    `print("엔드포인트 상태를 확인하려면 다음 명령을 사용하세요:")

`    `print(f"aws sagemaker describe-endpoint --endpoint-name {endpoint\_name}")

`    `return endpoint\_name

if \_\_name\_\_ == "\_\_main\_\_":

`    `args = parse\_args()

`    `endpoint\_name = deploy\_model\_to\_sagemaker(args)

`    `print(f"배포 프로세스 시작됨. 엔드포인트 이름: {endpoint\_name}")
## **참고 자료 및 리소스** 
### **1. 프레임워크 및 라이브러리**
- **FastAPI** : 고성능 Python 웹 프레임워크 - [공식 문서 ](https://fastapi.tiangolo.com/)
- **React** : 사용자 인터페이스 라이브러리 - [공식 문서 ](https://reactjs.org/)
- **SQLAlchemy** : Python SQL 툴킷 및 ORM - [공식 문서 ](https://www.sqlalchemy.org/)
- **PyTorch** : ML 프레임워크 - [공식 문서 ](https://pytorch.org/)
- **Transformers** : 텍스트 모델 라이브러리 - [공식 문서 ](https://huggingface.co/docs/transformers/)
- **PEFT** : 파라미터 효율적 파인튜닝 - [공식 문서 ](https://huggingface.co/docs/peft/)
### **2. AWS 서비스**
- **ECS** : 컨테이너 오케스트레이션 - [AWS 문서 ](https://aws.amazon.com/ecs/)
- **RDS** : 관계형 데이터베이스 - [AWS 문서 ](https://aws.amazon.com/rds/)
- **SageMaker** : ML 모델 훈련 및 배포 - [AWS 문서 ](https://aws.amazon.com/sagemaker/)
- **ECR** : 컨테이너 레지스트리 - [AWS 문서 ](https://aws.amazon.com/ecr/)
### **3. 인프라 및 배포**
- **Docker** : 컨테이너화 플랫폼 - [공식 문서 ](https://docs.docker.com/)
- **Terraform** : 인프라 관리 툴 - [공식 문서 ](https://www.terraform.io/docs)
- **CloudFormation** : AWS 인프라 정의 - [AWS 문서 ](https://aws.amazon.com/cloudformation/)
### **4. 모델 및 AI**
- **Anthropic Claude** : 상용 AI 모델 - [공식 문서 ](https://docs.anthropic.com/)
- **Llama** : Meta의 오픈소스 LLM - [Hugging Face ](https://huggingface.co/meta-llama)
- **SageMaker 모델 배포** : [AWS 블로그 ](https://aws.amazon.com/blogs/machine-learning/deploy-large-models-on-amazon-sagemaker/)
- **vLLM** : 고속 LLM 서빙 - [GitHub ](https://github.com/vllm-project/vllm)
### **5. 참고 프로젝트**
- **FastAPI 풀스택 템플릿** : [GitHub ](https://github.com/fastapi/full-stack-fastapi-template)
- **SageMaker 모델 배포 가이드** : [블로그 ](https://medium.com/p/58358ac7ad9c)
- **Flask와 React 보일러플레이트** : [GitHub ](https://github.com/thedev-junyoung/FastAPI-React-boilerplate)

이 설계는 CR 프로젝트를 효과적으로 구현하기 위한 종합적인 접근 방식을 제시합니다. 프로젝트의 규모, 예산, 팀 역량에 따라 적절히 조정하여 활용하세요. 

# **2-3. 회원 관리 및 과금 방식에 대한 아이디어** 
### **개요**
-----
(쉬운 설명) 

CR 프로젝트는 비영리 철학을 바탕으로 '기사 품질 평가'라는 사회적 가치를 실현하기 위해 설계됩니다. 우리는 효율적인 기술 구조와 간편한 접근성을 통해 많은 시민이 참여할 수 있도록 할 계획입니다. 

이 플랫폼은 '클라우드 서비스'라는 방식을 사용합니다. 이것은 큰 컴퓨터 서버를 직접 구매하지 않고, 필요할 때만 빌려 쓰는 것과 같습니다. 사용량이 적을 땐 적게 쓰고, 많을 땐 자동으로 확장되어 비용을 절약할 수 있습니다. 이런 방식으로 하루 방문자가 10만 명이라도 월 수십 달러 정도의 비용만 발생합니다. 

회원 가입은 번거로운 절차 없이 카카오, 네이버, 구글 등 이미 사용 중인 소셜 계정으로 바로 로그인할 수 있게 만들 예정입니다. 이렇게 하면 새로운 아이디와 비밀번호를 만들고 기억할 필요 없이 쉽게 서비스를 이용할 수 있습니다. 

재정적으로는 비영리 법인 형태로 운영하며, 초기에는 다양한 지원금과 후원으로 비용을 충당합니다. 후원금이 운영비를 초과하면 그 차액은 전액 공익 단체에 기부하거나 프로젝트 기능 확장에 재투자할 것입니다. 이런 투명한 재정 운영은 시그널이나 프로퍼블리카 같은 성공적인 비영리 프로젝트 사례에서 볼 수 있습니다. 

-----
(구체적인 설명) 

이 프로젝트는 **AWS 서버리스 인프라로 탄력적이고 비용 효율적인 구조** 를 마련하되, **소셜 로그인 중심의 간편 회원가입** 으로 일반 시민이 쉽게 접근하도록 해야 합니다. 그리고 **비영리 모토** 에 걸맞게, 초기에는 AWS 크레딧과 소규모 기부·후원으로 비용을 충당하고, 구조적으로 어느 정도 안정화된 이후에도 **운영비를 최소화** 함으로써 유료화 없이 서비스를 계속 제공할 수 있습니다. 만약 기부가 늘어서 수입이 필요한 지출을 초과하면, 그 차액은 **전부 공익적 단체에 기부** 하거나 프로젝트의 사회 공헌 활동에 재투자해, 이익이 사유화되지 않게끔 해야 합니다. 

서버리스 기반 API Gateway + Lambda + DynamoDB(혹은 RDS) 사용 시, 최대 10만 명 하루 방문을 처리해도 **사용량에 비례한 비용** 만 지불하므로, 대체로 월 수십 달러 수준으로도 서비스가 가능하리라 예상됩니다. 게다가 캐싱, 배치 처리, 모니터링, 최적화 등을 통해 비용을 더욱 줄일 수 있습니다. 사용자 측면에서는, 소셜 로그인이 제공되어 가입 장벽이 매우 낮아지고, 광고나 과금 없이 누구나 기사를 분석해볼 수 있으니 참여도가 올라갈 것입니다. 

재정적으로는 비영리 법인 형태를 갖추고, (재단·정부·후원자·시민단체) 등 다양한 경로에서 기부나 후원금을 받고, **프로젝트 운영비 외에 남는 금액은 전액 기부** 한다고 투명하게 안내하면, 사용자들은 “기사 신뢰도 평가”라는 사회적 가치에 기꺼이 후원할 가능성이 높아집니다. 시그널(Signal)·프로퍼블리카(ProPublica) 등의 사례는, 이런 방식으로도 충분히 높은 영향력과 신뢰도를 갖춘 채 운영이 가능함을 보여주고 있습니다. 

이 계획은 데이터와 이미 검증된 사례에 근거를 두고 있으며, 기술적 성능(서버리스 아키텍처), 사용자 확보(간편 소셜 로그인), 재정적 안정(비영리 구조 및 기부/후원)을 균형 있게 결합한 **최적의 해법** 이라 할 수 있습니다. 
## **1. 기본 원칙** 
- **비영리 모토** : 상업적 이익 추구가 아닌 사회적 가치 중심 운영 
- **AWS 서버리스 인프라** : 탄력적이고 비용 효율적인 구조로 설계 
- **소셜 로그인 중심** : 간편한 회원가입으로 접근성 극대화 
- **최소 운영비** : 초기에는 AWS 크레딧과 소규모 기부·후원으로 비용 충당 
- **수익 재투자** : 운영비 초과 수입은 전액 공익적 단체에 기부 또는 프로젝트 확장에 재투자 
## **2. 인프라 및 비용 구조** 
- **서버리스 아키텍처** : API Gateway + Lambda + DynamoDB(혹은 RDS) 조합 
- **예상 운영 비용** : 10만 명/일 방문 처리 시에도 월 수십 달러 수준으로 운영 가능 
- **비용 최적화** : 캐싱, 배치 처리, 모니터링을 통한 지속적 비용 절감 
- **법적 구조** : 비영리 법인 형태로 재정적 투명성 확보 
- **자금 조달** : 다양한 경로(재단·정부·후원자·시민단체)의 기부/후원금 활용 
## **3. 로그인 및 회원 관리 시스템** 
- **이중 인증 시스템** : 소셜 로그인과 기본 인증 방식을 모두 지원 
- **소셜 로그인 장점** : 간편한 접근성과 사용 편의성 제공 
- **기본 인증 장점** : 개인정보 노출 최소화와 높은 보안성 제공 
- **선택권 제공** : 사용자 선호도에 따라 인증 방식 선택 가능 
## **4. 로그인 없는 건별 과금 시스템 설계** 
### **4.1 기본 구조**
- **토큰 기반 일회성 결제** : 사용자가 기사 분석 시마다 일회성 결제 진행 
- **익명 세션 관리** : 브라우저 세션/로컬 스토리지로 결제 상태 임시 저장 
- **결제 API 직접 연동** : PG사(결제대행사) API를 프론트엔드에서 직접 호출 
- **캐싱 시스템** : 동일 기사 중복 분석 방지 및 비용 절감 
- **레이트 리밋 적용** : 서비스 안정성 보장 
- **최적화된 결제 옵션** : PG사 수수료를 고려한 효율적 결제 모델 
### **4.2 사용자 흐름**
1. 사용자가 기사 URL 입력 또는 텍스트 붙여넣기 
2. 시스템이 기사 길이/복잡도 확인 후 예상 비용 표시 
3. 사용자가 "분석 시작" 버튼 클릭 
4. 간소화된 결제 창 표시 (카드 정보 또는 간편결제 선택) 
5. 결제 완료 즉시 분석 시작 및 결과 제공 
6. 분석 결과는 고유 URL로 저장되어 사용자에게 제공 (이메일 발송 옵션) 
### **4.3 기술적 구현 방안**
### **프론트엔드 구현** 
// 분석 요청 및 결제 처리 흐름

async function requestAnalysis() {

`  `const articleData = getArticleData(); // URL 또는 텍스트 추출

`  `const articleHash = await generateHash(articleData); // 기사 내용 해시 생성

`  `// 캐시된 결과 확인

`  `const cachedResult = await api.checkCachedResult(articleHash);

`  `if (cachedResult.exists) {

`    `// 캐시된 결과가 있다면 할인 가격 제시

`    `const discountedCost = cachedResult.cost \* 0.3; // 70% 할인

`    `if (confirmDiscountedAnalysis(discountedCost)) {

`      `const paymentResult = await processPayment(discountedCost);

`      `if (paymentResult.success) {

`        `displayResult(cachedResult.analysis);

`        `return;

`      `}

`    `}

`  `}

`  `// 비용 계산 요청

`  `const { cost, sessionToken } = await api.calculateCost(articleData);

`  `// 사용자에게 비용 표시 및 확인

`  `if (!confirmPayment(cost)) return;

`  `// 결제 창 호출 (PG사 API 직접 연동)

`  `const paymentResult = await paymentGateway.requestPayment({

`    `amount: cost,

`    `orderName: "기사 분석 서비스",

`    `sessionToken: sessionToken

`  `});

`  `if (paymentResult.success) {

`    `// 결제 성공 시 분석 요청

`    `const analysisResult = await api.analyzeArticle(

`      `articleData,

`      `paymentResult.paymentToken

`    `);

`    `// 분석 결과 표시

`    `displayResult(analysisResult);

`    `// 결과 URL 생성 및 공유 옵션 제공

`    `const shareUrl = analysisResult.shareUrl;

`    `offerShareOptions(shareUrl);

`  `}

}
### **백엔드 구현** 
\# 캐시 확인 기능

@app.route('/api/check-cached-result', methods=['POST'])

def check\_cached\_result():

`    `article\_hash = request.json.get('articleHash')

`    `# Redis 또는 다른 캐시 시스템에서 결과 조회

`    `cached\_analysis = cache.get(f"analysis:{article\_hash}")

`    `if cached\_analysis:

`        `return jsonify({

`            `'exists': True,

`            `'cost': calculate\_discounted\_cost(cached\_analysis),

`            `'timestamp': cached\_analysis.get('timestamp')

`        `})

`    `return jsonify({'exists': False})

\# 비용 계산 API

@app.route('/api/calculate-cost', methods=['POST'])

def calculate\_cost():

`    `article\_data = request.json.get('articleData')

`    `# 기사 길이, 복잡도 등으로 비용 계산

`    `word\_count = len(article\_data.split())

`    `base\_cost = 300  # 기본 비용 300원

`    `if word\_count > 1000:

`        `cost = base\_cost + ((word\_count - 1000) // 500) \* 100

`    `else:

`        `cost = base\_cost

`    `# 일회용 세션 토큰 생성

`    `session\_token = generate\_unique\_token()

`    `cache.set(session\_token, {

`        `'article\_data': article\_data,

`        `'cost': cost,

`        `'timestamp': datetime.now().isoformat()

`    `}, timeout=1800)  # 30분 유효

`    `return jsonify({

`        `'cost': cost,

`        `'sessionToken': session\_token

`    `})

\# 분석 실행 API (레이트 리밋 적용)

@app.route('/api/analyze', methods=['POST'])

@limiter.limit("5 per minute") # IP당 분당 5회로 제한

def analyze\_article():

`    `payment\_token = request.json.get('paymentToken')

`    `session\_token = request.json.get('sessionToken')

`    `# 결제 검증

`    `if not verify\_payment(payment\_token):

`        `return jsonify({'error': 'Payment verification failed'}), 400

`    `# 세션 검증

`    `cached\_data = cache.get(session\_token)

`    `if not cached\_data:

`        `return jsonify({'error': 'Session expired'}), 400

`    `# 분석 실행

`    `article\_data = cached\_data['article\_data']

`    `analysis\_result = perform\_analysis(article\_data)

`    `# 익명화 처리 및 결과 저장

`    `result\_id = store\_analysis\_result(analysis\_result, article\_data)

`    `share\_url = f"{config.BASE\_URL}/results/{result\_id}"

`    `# 영수증 ID 생성 (필요시 메일 발송용)

`    `receipt\_id = generate\_receipt\_id(payment\_token)

`    `return jsonify({

`        `'result': analysis\_result,

`        `'shareUrl': share\_url,

`        `'receiptId': receipt\_id

`    `})

\# 데이터 익명화 및 저장

def store\_analysis\_result(result, article\_data):

`    `# 저장 전 익명화 처리

`    `anonymized\_article = anonymize\_sensitive\_data(article\_data)

`    `# 개인식별정보(PII) 제거

`    `result = remove\_pii\_from\_result(result)

`    `# 결과 저장 시 암호화

`    `encrypted\_result = encrypt\_data(result)

`    `# 임시 ID 생성 (추적 불가능한 UUID)

`    `result\_id = generate\_untraceable\_uuid()

`    `# 저장 및 자동 삭제 일정 설정 (30일 후)

`    `db.store\_with\_ttl(result\_id, encrypted\_result, ttl=30\*24\*60\*60)

`    `return result\_id

\# 최적 가격 계산

def calculate\_optimal\_cost(article\_data):

`    `word\_count = len(article\_data.split())

`    `# 기본 원가 계산

`    `raw\_cost = calculate\_raw\_cost(word\_count)

`    `# PG사 수수료 고려 (일반적으로 3.5% + 기본 수수료)

`    `min\_viable\_payment = 500  # 최소 500원 (PG사 수수료 효율성 고려)

`    `if raw\_cost < min\_viable\_payment:

`        `return min\_viable\_payment

`    `# 사용자 심리적 가격점 고려 (예: 900원보다는 990원)

`    `return optimize\_price\_point(raw\_cost)
### **4.4 지불 옵션 다양화**
1. **신용카드 일회성 결제** : 표준 카드 결제 (최소 결제액 제한) 
2. **소액 결제 패키지** : 선불 방식으로 포인트/크레딧 구매 가능 (예: "5,000원에 10회 분석 패키지") 
3. **간편결제 연동** : 카카오페이, 네이버페이, 토스페이 등 연동 
### **4.5 익명성 보장과 데이터 관리**
- **개인정보 최소화** : 결제 정보는 PG사에서 관리, 서비스에는 최소 정보만 저장 
- **분석 결과 임시 저장** : 공유 URL은 제한된 기간(예: 30일) 동안만 유효 
- **이메일 공유 옵션** : 이메일 입력 시 결과 링크 발송 (선택 사항) 
- **익명 세션 관리** : 브라우저 지문이나 세션 ID로 단기간 내 반복 사용 추적 
### **4.6 장단점 분석**
**장점** : 

- 즉시 사용 가능 (회원가입 장벽 제거) 
- 개인정보 수집 최소화로 보안 리스크 감소 
- 일회성 사용자의 접근성 향상 
- 기사별 차등 과금 가능 (길이/복잡도 기준) 

**단점** : 

- 반복 사용자는 매번 결제 정보 입력 필요 
- 사용 이력 관리 어려움 
- 최소 결제 금액으로 인한 소액 과금 비효율 (PG사 수수료 고려) 
- 결제 취소/환불 프로세스 복잡 
### **4.7 하이브리드 접근법**
- **기본** : 로그인 없이 건별 과금 
- **옵션** : 더 많은 기능이 필요한 사용자를 위한 선택적 회원가입 
  - 분석 이력 관리 
  - 프리미엄 기능 (대량 분석, 언론사별 비교 등) 
  - 구독 모델 (월 5,000원에 무제한 분석) 
## **5. 추가 기술적 개선 요소** 
### **5.1 오픈소스 접근법 적용**
- **투명성 강화** : 분석 알고리즘 핵심 로직 공개 (GitHub) 
- **커뮤니티 기여** : 문제 패턴 데이터베이스를 오픈소스화하여 집단지성 활용 
- **API 문서화** : 외부 개발자가 연동할 수 있도록 API 문서 공개 
### **5.2 종합 시스템 아키텍처**
[사용자 브라우저]

`    `│

`    `▼

[프론트엔드 (React)]

`    `│

`    `├── 기사 입력 처리

`    `├── 해시 생성 및 캐시 확인

`    `├── 결제 프로세스 연동

`    `│

`    `▼

[API 게이트웨이 + 레이트 리밋]

`    `│

`    `├── [캐싱 레이어 (Redis)]

`    `│     └── 동일 기사 분석 결과 캐싱

`    `│

`    `├── [분석 엔진 (Python/ML)]

`    `│     └── 기사 품질 측정

`    `│

`    `├── [결제 시스템]

`    `│     ├── 최적 가격 계산

`    `│     └── PG사 연동

`    `│

`    `└── [데이터 저장소]

`          `├── 익명화된 분석 결과 (TTL 적용)

`          `└── 통계/분석 데이터
## **6. 벤치마킹 및 사례 연구** 
### **6.1 "실비 정산" 방식의 디지털 서비스 사례**
**Internet Archive** : 

- 접근 방식: 기부 + 일부 서비스 유료화 
- 운영 방식: 대부분 무료 제공, 특정 서비스만 실비용 기준 제한적 과금 
- 투명성: 연간 재정보고서 공개로 비용 사용 투명하게 공유 
- 적용점: 주요 기능은 무료로 제공하면서 대용량/전문적 기능만 실비 정산 

**ProPublica Data Store** : 

- 접근 방식: 공익 데이터 무료 + 상업적 활용 유료 정책 
- 운영 방식: 비영리 목적 무료 API, 상업적 사용자 유료 라이선싱 
- 가격 구조: 데이터셋 종류에 따라 $200~$10,000 차등 
- 적용점: 사용 목적에 따른 차등 과금 모델 

**Common Voice (Mozilla)** : 

- 접근 방식: 크라우드소싱 + 자원봉사 + 기부 
- 운영 방식: 데이터 기여자 커뮤니티 구축 + 기관 파트너십 
- 지속가능성: 데이터 활용 기관의 기여금 + 재단 지원 
- 적용점: 사용자 참여와 데이터 기여 모델 결합 
### **6.2 하이브리드 비즈니스 모델 성공 사례**
**Knight Foundation's American Press Institute** : 

- 접근 방식: 재단 지원 + 미디어 파트너십 + 유료 리서치 
- 운영 방식: 기본 지표는 무료, 고급 분석과 맞춤 연구는 유료 
- 지속가능성: 초기 재단 지원으로 시작해 점진적으로 자체 수익 모델 강화 
- 적용점: CR 프로젝트도 초기 시민단체/재단 지원으로 시작해 점진적 자립화 

**Wikipedia(위키미디어 재단)** : 

- 접근 방식: 완전 무료 접근 + 자발적 기부 시스템 
- 운영 방식: 연 1회 기부 캠페인 + 기관 파트너십 
- 투명성: 모든 비용 사용처 상세 공개, 실시간 기부 현황 대시보드 
- 적용점: 크레딧 시스템과 함께 자발적 기부 옵션 병행 가능 

**Global Witness Digital Investigations** : 

- 접근 방식: 비영리 + 제한적 상업 서비스 
- 운영 방식: 조사 보고서는 무료 공개, 전문 분석 도구는 기관 라이선싱 
- 지속가능성: 핵심 미션은 비영리로 유지, 부가 서비스로 운영 비용 충당 
- 적용점: CR의 핵심 서비스(기사 평가)는 최소 비용으로, 고급 API나 대량 분석은 차등 과금 

# **2-4. 나쁜 저널리즘 요소 식별 및 제출 가이드** 
본 가이드는 미디어 전문가, 언론학자, 교육개혁가, 인권 활동가, 대안적 경제학자 등 다양한 분야의 전문가들이 ‘나쁜 저널리즘’ 사례를 효과적으로 식별하고 제출하는 데 도움을 주기 위해 작성되었습니다. 
## **1. 나쁜 저널리즘 요소 식별 방법** 
### 취재원 관련 문제** 
- 익명 취재원 남용: 핵심 주장이나 정보가 실명 확인이 불가능한 출처에 의존할 때 
- 취재원 다양성 부족: 한쪽 입장만 대변하는 취재원으로만 구성된 경우 
- 권위에 의존한 취재: 취재원의 직업이나 지위만으로 정보의 신뢰성을 대체하는 경우 
- 취재원 편향: 특정 이해관계나 입장을 가진 취재원만 선별적으로 인용 
### 문장 구조 및 표현 문제** 
- 무주체 피동형 문장: "알려졌다", "전해졌다" 등 정보 출처를 명확히 하지 않는 표현 
- 주관적 인용구 술어: "주장했다", "항변했다", "강조했다" 등 기자의 주관이 담긴 인용 술어 
- 과장된 수식어: 감정적 반응을 유도하는 과도한 형용사/부사 사용 
- 불필요한 생략: 독자의 이해에 필수적인 맥락 정보 생략 
### 기사 구조 및 내용 문제** 
- 헤드라인-내용 불일치: 클릭을 유도하기 위해 과장된 제목 사용 
- 사실과 의견 혼합: 기자의 주관적 해석이 객관적 사실 보도와 구분 없이 섞임 
- 균형성 결여: 중요한 반대 관점이나 이해관계자 입장 누락 
- 맥락 제거 인용: 원래 맥락에서 벗어난 부분적 인용으로 의미 왜곡 
## **2. 문제 요소 제출 양식** 
문제적 기사를 발견하셨을 때, 아래 템플릿을 사용하여 제출해 주시기 바랍니다: 

<문제요소>

기사 URL: [링크]

기사 제목: [제목]

발행일: [날짜]

언론사: [매체명]

[1] 문제 유형: [취재원 투명성/객관적 언어/정보 균형성 등 카테고리]

`    `문제 부분: [문제가 있는 실제 텍스트]

`    `위치: [문단 번호 또는 위치 정보]

`    `문제 설명: [왜 이것이 문제인지 구체적 설명]

`    `심각도: [상/중/하]

[2] 문제 유형: ...

`    `(추가 문제 요소에 대해 동일한 형식으로 계속)

종합 평가:

\- 주요 문제점 요약

\- 전반적인 품질 평가 (0점 만점 기준, 마이너스 점수 부여)

\- 이 기사가 대표하는 '나쁜 저널리즘' 패턴

</문제요소>
## **3. 제출 방법 및 처리 과정** 
### 1\. 초기 분석 단계
- 각 전문가는 자신의 전문 분야와 관련된 기사 20-30개를 선택하여 분석 
- 위의 템플릿을 사용하여 문제 요소를 상세히 기록 
- 분석 결과는 프로젝트 온라인 소통 공간(Discord/GitHub…)에 업로드 
### 2\. 데이터 정제 단계
- 수집된 분석 자료는 구조화된 데이터로 변환 
- 각 문제 요소를 별도의 훈련 예시로 처리 
- 유사한 문제 패턴을 그룹화하여 분류 체계 구축 
### 3\. 모델 학습 활용 방식
- 수집된 예시들은 LLM 파인튜닝 또는 프롬프트 엔지니어링의 기초 자료로 활용 
- 문제 유형별 탐지 모델을 개별적으로 훈련 후 통합 
- 전문가 제안 대안은 개선 제안 생성 모델 학습에 활용 
### 4\. 지속적 피드백 과정
- 모델이 식별한 문제 요소에 대해 정기적으로 전문가 검증 수행 
- 오탐지 사례를 수집하여 모델 개선에 활용 
- 새로운 유형의 '나쁜 저널리즘' 패턴 발견 시 즉시 공유 및 모델 업데이트 

이 가이드라인을 통해 다양한 전문가들의 일관된 형식의 피드백을 수집하고, 이를 AI 모델 학습에 효과적으로 활용할 수 있을 것입니다. 

# **2-5. 문제적 표현 패턴**(샘플)
### 1\. 무주체 피동형 표현 패턴** 
- 피동형 종결 표현 

  \* "~로 알려졌다", "~로 전해졌다", "~로 관측된다", "~로 전망된다", "~(이)라고 한다" 

  \* "~로 분석된다", "~로 해석된다", "~로 풀이된다", "~로 받아들여진다", "~로 판단된다" 

  \* "~로 이해된다", "~인 것으로 읽힌다", "~과 겹쳐진다", "~할지 주목된다" 

- 부적절한 피동형 

  \* "~로 조사됐다" 

  \* "~로 분석됐다" 

  \* "~관심이 모아진다" 

  \* "~되어진다" (이중피동/겹피동) 
### 2\. 익명 취재원 표현 패턴** 
- 모호한 취재원 표시 

  \* "한 전문가", "관계자", "고위 관계자", "당국자", "소식통", "측근", "핵심 측근" 

  \* "~에 따르면", "~의 관측", "~의 전망" 
### 3\. 간접인용서술과 가정판단서술** 
- 간접인용서술 

  \* "~라는 평가다", "~라는 진단이다", "~라는 지적이다", "~라는 비판이다" 

  \* "~라는 목소리가 높다", "~라는 시각이 우세하다", "~는 분위기다" 

- 가정판단서술 

  \* "~라는 전망이다", "~라는 관측이다", "~라는 예상이다" 
### 4\. 윤색적 표현과 주관적 술어** 
- 감정을 자극하는 표현 

  \* "애처롭다 못해 눈물겹다", "~로 심각하다" 

- 불확실성 강조 표현 

  \* "논란이 예상된다", "의혹을 산다", "혼란을 유발한다" 

  \* "~할 가능성이 높다", "점쳐진다", "감지된다" 

- 인용구의 주관적 술어 

  \* "~고 강조했다", "~고 주장했다", "~고 촉구했다", "~고 비판했다", "~고 압박했다" 

본 부록에는 대표적인 문제적 표현 패턴만 포함되어 있으며, 전체 패턴 목록과 상세 설명은 별도 기술 문서에서 관리합니다. 

# **2-6. 평가 결과의 일관성 문제** 
## **문제 정의: 평가 결과의 일관성 도전 과제** 
CR 프로젝트는 기사의 품질을 정량적으로 측정하는 AI 기반 플랫폼을 구축하는 것을 목표로 합니다. 그러나 동일한 기사에 대해서도 환경 조건과 맥락에 따라 평가 결과가 달라질 수 있으며 , 특히 LLM 업데이트나 평가 기준 수정 시 평가 결과의 일관성이 흔들릴 가능성 이 있습니다. 이는 다음과 같은 요인에서 비롯됩니다: 

- **LLM 업데이트** : 모델 파라미터 변화로 인한 출력 변동 
- **평가 기준 수정** : 기준 변경에 따른 점수 산출 방식 변화 
- **맥락 변화** : 사회적, 시간적 맥락의 변화에 따른 해석 차이 

이러한 변동성은 사용자 신뢰와 플랫폼 신뢰성에 직접적인 영향을 미치므로, 체계적인 일관성 유지 방안이 필요 합니다. 
## **표준화된 평가 체계 구축** 
### **평가 기준의 체계적 표준화** 
- **명확한 메트릭 정의** : 
  - 평가 항목(예: 취재원 투명성, 객관적 언어 사용)을 정량화 가능한 지표로 전환 
  - 예: "익명 취재원 사용 빈도" = 익명 취재원 수 / 전체 취재원 수 × 100 
  - 정량화된 기준은 주관적 해석의 여지를 줄이고 일관성을 높임 
- **다차원 매트릭스 방식 도입** : 
  - 문제 패턴(무주체 피동형 표현, 익명 취재원 등)과 저널리즘 가치 차원(진실성, 투명성 등)의 매트릭스 구성 
  - 각 패턴이 특정 차원에 미치는 영향을 수치화하여 종합 점수 산출 
  - 예: "~로 알려졌다" 표현은 투명성에 -20점, 진실성에 -15점 등의 영향을 미침 
- **규범 체계 연동** : 
  - 한국기자협회 윤리강령, 신문윤리실천요강 등 기존 규범과 평가 기준 연계 
  - 평가 결과에 해당 규범 항목 명시하여 설득력 강화 
### **평가 기준 문서화** 
- **상세 평가 루브릭 개발** : 
  - 각 평가 항목별 점수 기준 및 예시 명확화 
  - ISO 9001과 같은 품질 관리 절차 참조하여 표준화 
- **기준의 투명한 공개** : 
  - 모든 평가 기준을 사용자에게 투명하게 공개 
  - 평가 기준의 근거와 적용 사례 제공 
## **모델 관리 및 버전 통제** 
### **버전 관리 시스템 도입** 
- **체계적 버전 관리** : 
  - 모델과 평가 기준에 고유 버전 번호 부여 (예: LLM v1.0, 평가 기준 v2.1) 
  - GitHub와 같은 버전 관리 시스템 활용 
  - 평가 결과에 사용된 모델/기준 버전 메타데이터 기록 
- **기준선(Baseline) 설정** : 
  - 초기 릴리스를 기준점으로 설정하고 변화 추적 
  - 주요 업데이트마다 새로운 기준선 설정 
### **표준 테스트 데이터셋 구축** 
- **골든 데이터셋(Golden Dataset) 구축** : 
  - 300-500개의 다양한 품질 수준의 기사 샘플 구성 
  - 전문가 패널이 평가한 표준 점수 설정 
  - 모델/기준 변경 시 일관성 검증에 활용 
- **경계 사례(Edge Cases) 포함** : 
  - 평가가 어려운 특수 사례들을 명시적으로 포함 
  - 시스템 한계 검증에 활용 
### **다중 모델 앙상블 접근법** 
- **모델 앙상블 활용** : 
  - 여러 버전의 모델을 함께 사용하여 개별 모델 변동성 상쇄 
  - 다양한 관점에서의 평가를 종합하여 안정성 확보 
- **점진적 업데이트 전략** : 
  - 모델을 일괄 교체하지 않고 점진적으로 업데이트 
  - 신규 모델의 가중치를 점진적으로 증가시켜 급격한 변화 방지 
## **평가 결과 안정화 기법** 
### **하이브리드 평가 시스템** 
- **규칙 기반 + AI 평가 병행** : 
  - 객관적으로 측정 가능한 요소(무주체 피동형 표현 수, 익명 취재원 비율)는 규칙 기반으로 구현 
  - 맥락 이해가 필요한 복잡한 평가(균형성, 심층성)는 LLM 활용 
  - 두 평가 결과 가중 결합으로 최종 점수 산출 
- **LLM-as-judge 접근법 활용** : 
  - 다른 LLM을 평가자로 활용하여 기사 품질 평가 
  - 평가 과정과 근거 설명을 함께 제공하여 투명성 확보 
### **자가학습 평가자(Self-Taught Evaluator) 도입** 
- **메타의 자가학습 평가자 방식 적용** : 
  - 인간 라벨링 데이터 없이도 기사 품질 평가 가능 
  - 기본 응답 생성 후 지침 수정을 통한 반복 학습 
  - 평가 정확도와 일관성 동시 향상 
### **보정 메커니즘 구현** 
- **모델 간 보정 계수 개발** : 
  - 새 모델과 기존 모델 간 출력 차이 분석 
  - 차이를 보정하는 변환 함수 개발 
- **분야별/맥락별 보정** : 
  - 정치, 경제, 사회 등 주제별 맥락 차이를 반영한 보정 계수 적용 
  - 기사 유형(스트레이트, 해설)에 따른 평가 기준 차별화 
## **지속적 모니터링 및 피드백 체계** 
### **자동화된 모니터링 시스템** 
- **데이터 드리프트 감지** : 
  - 모델 출력 분포 변화를 실시간 추적 
  - 임계값 이상 변동 시 자동 알림 시스템 구축 
- **정기적 성능 평가** : 
  - 표준 데이터셋으로 주기적 성능 테스트 
  - 일관성 지표(ICC, CV) 추적 및 보고 
### **사용자 피드백 루프 구축** 
- **피드백 수집 채널** : 
  - 평가 결과에 대한 사용자 의견 수집 채널 마련 
  - 다양한 사용자층(일반 독자, 언론인, 연구자)의 피드백 종합 
- **크라우드소싱 검증** : 
  - 사용자 피드백을 통한 분산형 검증 체계 구축 
  - 평가 결과의 공정성과 정확성에 대한 집단 지성 활용 
### **전문가 검토 체계** 
- **정기적 전문가 감사** : 
  - 미디어 전문가 패널이 평가 시스템 정기 검토 
  - 사회적 맥락 변화와 언론 환경 변화 반영 
- **오류 분석 프로세스** : 
  - 사용자 피드백과 자동 감지를 통한 오류 식별 
  - 원인 분석 및 시스템 개선에 반영 
## **변경 관리 프로세스** 
### **평가 기준 변경 시 프로세스** 
- **변경 이력 투명한 공개** : 
  - 평가 기준 변경 사항과 근거 명확히 공개 
  - 변경이 미치는 영향 예측 및 공유 
- **이중 평가 기간 운영** : 
  - 새로운 평가 기준과 기존 평가 기준 일정 기간 병행 
  - 사용자에게 적응 기간 제공 
### **과거 평가 결과 재계산** 
- **소급 적용 메커니즘** : 
  - 기준 변경 시 과거 평가 결과 재계산 기능 제공 
  - 시계열 비교 가능성 유지 
- **버전 간 비교 기능** : 
  - 사용자가 동일 기사에 대해 다양한 버전의 평가 결과 비교 가능 
  - 변화의 이유와 영향 투명하게 제시 
### **A/B 테스트 활용** 
- **새 모델/기준의 단계적 도입** : 
  - 제한된 사용자 그룹에 먼저 적용 
  - 피드백 수집 및 개선 후 전체 적용 
- **병행 테스트 기간** : 
  - 새로운 시스템 도입 전 최소 3개월 병행 운영 
  - 결과 차이 분석 및 보정 계수 도출 
## **결론 및 권장사항** 
CR 프로젝트에서 평가 결과의 일관성을 유지하기 위해서는 다음과 같은 종합적 접근이 필요합니다: 

1. **표준화된 평가 체계** 구축으로 기준의 객관성과 명확성 확보 
2. **체계적인 버전 관리와 테스트 데이터셋** 활용으로 변화 추적 및 검증 
3. **하이브리드 평가 시스템과 보정 메커니즘** 으로 안정성 강화 
4. **자동화된 모니터링과 피드백 루프** 를 통한 지속적 개선 
5. **투명한 변경 관리 프로세스** 로 사용자 신뢰 유지 

이러한 방안을 종합적으로 적용함으로써, LLM 업데이트나 평가 기준 수정에도 불구하고 CR 플랫폼은 일관성 있고 신뢰할 수 있는 기사 품질 평가를 제공할 수 있을 것입니다. 이는 "시민 주도의 언론 개혁"이라는 CR 프로젝트의 근본 목표를 달성하는 데 기여할 것입니다. 
