# Story 047: 알고리즘의 공정성

**장르**: 사회 드라마
**주제**: 데이터의 객관성과 편향의 문제
**시점**: 3인칭 관찰자
**분량**: 약 8,500자
**주인공**: 시민M (38세, CR 기획자) / 박서연 (35세, 데이터 과학자)
**시기**: 2024년 5월
**만남의 채널**: AI 윤리 세미나

---

## 프롤로그

'AI와 민주주의: 알고리즘이 사회에 미치는 영향' 세미나는 서울대학교 대강당에서 열렸다. 토요일 오후 2시. 참석자 150명. 대부분 대학원생, 연구자, IT 업계 종사자들이었다.

시민M은 뒷자리에 앉아 있었다. 세미나 주제가 CR 프로젝트와 관련이 있어 보여서 참석했다. 특히 세 번째 발표자가 관심을 끌었다. 박서연. KAIST 데이터 과학 연구소 연구원. 발표 제목: "추천 알고리즘의 편향성: 우리가 보는 뉴스는 정말 공정한가?"

박서연이 단상에 올랐다. 30대 중반. 검은 뿔테 안경. 간결한 복장. 노트북을 연결하고 첫 슬라이드를 띄웠다.

"우리는 매일 알고리즘이 추천하는 뉴스를 봅니다. 포털 사이트, SNS, 뉴스 앱. 모두 알고리즘이 선택한 기사입니다. 그런데 이 알고리즘은 공정할까요?"

슬라이드가 넘어갔다. 그래프 하나. X축은 정치 성향(진보-중도-보수), Y축은 노출 빈도. 두 개의 선. 하나는 사용자 A, 다른 하나는 사용자 B. 사용자 A는 진보 기사에 95% 노출. 사용자 B는 보수 기사에 92% 노출.

"이것이 필터 버블입니다. 알고리즘은 사용자가 클릭한 기사와 비슷한 기사를 계속 추천합니다. 결과적으로 사용자는 자신의 성향에 맞는 뉴스만 보게 됩니다. 다른 관점은 사라집니다."

시민M은 메모를 했다. 이것이 바로 CR이 해결하려는 문제 중 하나였다. 알고리즘이 아니라 사람이 평가하고, 그 평가를 투명하게 공유하는 방식.

발표가 끝나고 질의응답 시간. 시민M이 손을 들었다.

"만약 알고리즘이 아니라 시민들의 직접 평가로 기사를 추천한다면 어떨까요? 필터 버블을 벗어날 수 있을까요?"

박서연은 잠시 생각하더니 대답했다.

"흥미로운 질문입니다. 하지만 시민 평가에도 편향이 있을 수 있습니다. 사람들은 자신의 의견을 확인해주는 기사에 높은 점수를 줄 가능성이 높습니다. 결과적으로 알고리즘 필터 버블과 비슷한 효과가 나타날 수 있습니다."

"그럼 어떻게 해야 할까요?"

"편향을 인지하고 조정하는 메커니즘이 필요합니다. 예를 들어, 사용자의 평가 패턴을 분석해서 편향을 측정하고, 그에 따라 가중치를 조정하는 방식입니다."

세미나가 끝나고 시민M은 박서연에게 다가갔다.

"발표 잘 들었습니다. 질문했던 사람인데요."

"네, 기억나요."

"혹시 시간 있으시면 커피 한잔 하면서 이야기 나눌 수 있을까요? 제가 실제로 시민 평가 플랫폼을 만들고 있거든요."

박서연은 시계를 봤다. 오후 5시. 다음 약속까지 2시간.

"좋아요. 근처 카페로 갈까요?"

---

## 1막: 데이터의 진실

카페는 대학가 특유의 조용한 분위기였다. 시민M과 박서연은 창가 자리에 앉았다. 시민M은 노트북을 열어 CR 베타 사이트를 보여줬다.

"이게 지금 만들고 있는 플랫폼입니다. Citizen Review. 시민이 언론을 평가하는 시스템이에요."

박서연은 화면을 찬찬히 봤다. 기사 목록, 평가 인터페이스, 언론사 신뢰도 점수. 간단하지만 명확한 구조.

"UI는 깔끔하네요. 누가 개발했어요?"

"백엔드 개발자랑 같이 하고 있어요. 아직 베타 버전이라 사용자는 몇십 명밖에 안 돼요."

박서연은 평가 인터페이스를 클릭했다. 별점 5개. 세부 항목: 정확성, 공정성, 깊이.

"평가 기준이 주관적이네요."

"네. 그게 문제인가요?"

"문제라기보다는... 한계예요. 정확성을 판단하려면 사실 확인이 필요한데, 대부분의 사람들은 그걸 안 해요. 그냥 자신의 믿음에 맞으면 정확하다고 평가하죠."

시민M은 고개를 끄덕였다. 예상했던 지적이었다.

"그래서 고민이에요. 어떻게 하면 더 객관적인 평가를 받을 수 있을까."

박서연은 노트북을 꺼냈다. 주피터 노트북을 열었다. 파이썬 코드와 그래프가 가득했다.

"제가 최근에 연구한 게 있어요. 뉴스 기사 평가의 편향성 분석. 1,000명의 사용자에게 같은 100개 기사를 평가하게 했어요. 그리고 패턴을 분석했죠."

그래프를 보여줬다. X축은 기사의 정치 성향, Y축은 평균 평가 점수. 진보 성향 사용자는 진보 기사에 8.2점, 보수 기사에 3.1점. 보수 성향 사용자는 반대. 보수 기사 8.5점, 진보 기사 2.9점.

"보세요. 사람들은 자기 성향에 맞는 기사에 높은 점수를 줘요. 내용과 무관하게. 이게 확증 편향입니다."

"그럼 시민 평가는 의미가 없나요?"

"의미가 없진 않아요. 하지만 raw data를 그대로 쓰면 안 돼요. 편향을 보정해야죠."

"어떻게요?"

박서연은 다음 슬라이드를 보여줬다. 복잡한 수식. 가중치, 베이지안 보정, 아웃라이어 제거.

"간단하게 설명하면, 각 사용자의 평가 패턴을 분석해서 편향 계수를 계산해요. 예를 들어, 누군가 진보 기사에만 높은 점수를 준다면, 그 사람의 진보 기사 평가는 가중치를 낮추고, 보수 기사 평가는 가중치를 높이는 거죠."

"그럼 결과가 달라지나요?"

"네. 보정 전에는 언론사 신뢰도가 정치 성향에 따라 극명하게 갈렸어요. 진보 언론은 진보 사용자에게만 높은 점수, 보수 언론은 보수 사용자에게만. 보정 후에는 훨씬 수렴했어요. 실제 품질을 반영하는 점수가 나왔죠."

시민M은 흥분했다. 이것이 CR에 필요한 기술이었다.

"이거 저희 플랫폼에 적용할 수 있을까요?"

박서연은 잠시 망설였다.

"적용은 가능해요. 근데..."

"근데요?"

"데이터가 필요해요. 편향을 측정하려면 각 사용자의 충분한 평가 데이터가 있어야 해요. 최소 20~30개 기사 평가. 그리고 다양한 성향의 기사를 평가해야 하고. 지금 사용자 몇십 명으로는 부족해요."

"사용자가 늘어나면요?"

"그럼 가능하죠. 수천 명, 수만 명이 되면."

시민M은 노트를 꺼내 적었다. '편향 보정 알고리즘. 사용자 수천 명 이상 필요.'

"서연 님, 혹시 이 알고리즘을 저희한테 제공해줄 수 있나요? 아니면 같이 작업할 수 있을까요?"

박서연은 커피를 마셨다. 시간을 버는 제스처. 생각이 복잡했다.

"솔직히 말씀드리면, 회의적이에요."

"왜요?"

"시민 평가 플랫폼이 이미 여러 번 시도됐어요. 다 실패했어요. 사용자 확보도 어렵고, 평가 품질도 낮고, 지속 가능성도 없고."

"저희는 다를 거예요."

"다들 그렇게 말해요. 근데 결국 똑같아요."

시민M은 잠시 침묵했다. 박서연의 회의는 합리적이었다. 데이터 과학자로서 과거 사례를 분석한 결과였다.

"그래도 시도는 해봐야 하지 않을까요?"

"왜요? 실패할 게 뻔한데."

"뻔하지 않을 수도 있어요. 타이밍이 다를 수 있고, 접근 방식이 다를 수 있고. 해보지 않으면 모르잖아요."

박서연은 시민M을 봤다. 진지한 얼굴이었다. 순진한 열정인지, 진짜 확신인지 판단이 안 섰다.

---

## 2막: 확률과 가능성

다음 주, 박서연은 CR 베타 사이트에 가입했다. 계정을 만들고, 기사 10개를 평가해봤다. 인터페이스는 간단했다. 별점을 클릭하면 바로 저장됐다. 세부 항목은 선택사항이었다.

평가 후 자신의 프로필을 봤다. '평가한 기사: 10개. 신뢰도: 아직 계산 중.' 신뢰도가 계산되려면 최소 20개 평가가 필요하다고 안내가 떴다.

박서연은 백엔드 코드가 궁금했다. 어떤 알고리즘을 쓰는지, 데이터베이스 구조는 어떤지. 시민M에게 메시지를 보냈다.

"코드 좀 볼 수 있을까요? GitHub 링크 주세요."

시민M이 링크를 보냈다. Public repository. 박서연은 코드를 읽기 시작했다. Node.js 백엔드. PostgreSQL. 평가 집계 로직. 신뢰도 계산 알고리즘.

알고리즘을 봤다. 단순한 가중 평균. 사용자의 평가 횟수에 따라 가중치가 올라가는 방식. 기본적이었지만 편향 보정은 없었다.

박서연은 코멘트를 달기 시작했다. "이 부분에서 편향 문제가 발생할 수 있음", "아웃라이어 처리 필요", "시간 가중치 고려". 20개 넘는 코멘트.

다음 날, 이준호(개발자)에게서 답장이 왔다.

"피드백 감사합니다. 맞는 지적이에요. 근데 지금 단계에서는 데이터가 부족해서 복잡한 알고리즘을 적용하기 어려워요. 사용자가 늘면 개선하려고 해요."

박서연은 이해했다. MVP 단계에서는 최소 기능만. 하지만 아쉬웠다. 제대로 된 알고리즘을 적용하면 훨씬 나아질 텐데.

주말에 시민M, 이준호와 온라인 회의를 했다. Zoom. 세 사람이 화면에 나타났다.

"서연 님, 코드 리뷰 감사해요. 지적하신 부분들 다 맞아요."

이준호가 말했다.

"근데 문제는 지금 당장 적용하기 어렵다는 거예요. 제가 통계 알고리즘까지 개발하기엔 시간이 부족해요."

시민M이 끼어들었다.

"그래서 서연 님께 부탁드리고 싶은 게 있어요. 편향 보정 알고리즘을 구현해주실 수 있나요? 파이썬 코드로 작성하시면 제가 백엔드에 통합할게요."

박서연은 망설였다.

"시간이 얼마나 걸릴지 모르겠는데요."

"천천히 하셔도 돼요. 저희도 급한 게 아니에요. 사용자가 어느 정도 쌓이면 적용하면 되니까."

"제가 왜 해야 하는데요? 저는 연구자지 개발자가 아니에요."

시민M이 대답했다.

"서연 님이 연구한 게 실제로 적용되는 걸 보고 싶지 않으세요? 논문에만 머물지 않고, 실제 플랫폼에서 작동하는 거."

박서연은 솔직히 끌렸다. 연구자로서 자신의 알고리즘이 실제 서비스에 적용되는 걸 보는 건 드문 경험이었다. 대부분의 연구는 논문으로 끝났다. 인용되고, 토론되고, 잊혔다.

"조건이 있어요."

"말씀하세요."

"이게 제 연구로 인정돼야 해요. 나중에 논문 쓸 때 데이터로 쓸 수 있어야 하고."

"당연하죠. 오히려 저희가 감사하죠."

"그리고 알고리즘의 투명성이 보장돼야 해요. 어떤 방식으로 편향을 보정하는지 사용자들이 알 수 있어야 해요."

"동의해요. 투명성은 저희 플랫폼의 핵심이에요."

박서연은 잠시 생각했다. 이 프로젝트가 성공할 확률은 낮았다. 데이터 과학자로서 냉정하게 평가하면 10% 미만. 하지만 0%는 아니었다. 그리고 실패하더라도 배우는 게 있을 것이다.

"좋아요. 해볼게요. 근데 제 본업이 우선이에요. 연구소 일 끝나고 시간 날 때만 할게요."

"감사합니다!"

시민M의 목소리에 흥분이 섞였다. 박서연은 웃었다. 오랜만에 느끼는 감정이었다. 연구가 현실이 되는 설렘.

---

## 3막: 코드와 데이터

박서연은 2주 동안 편향 보정 알고리즘을 구현했다. 퇴근 후 집에서. 주말 오전. 카페에서. 총 작업 시간 30시간.

파이썬 코드. 400줄. 함수: calculate_user_bias(), adjust_evaluation_weight(), compute_adjusted_trust_score(). 입력: 사용자 평가 데이터. 출력: 보정된 신뢰도 점수.

테스트 데이터로 검증했다. CR 베타 사용자 50명의 평가 데이터. 보정 전 신뢰도와 보정 후 신뢰도를 비교했다.

결과가 흥미로웠다. 보정 전에는 조선일보 5.2점, 한겨레 7.8점. 극명한 차이. 보정 후에는 조선일보 6.8점, 한겨레 7.1점. 수렴했다. 여전히 차이는 있었지만, 극단적이지 않았다.

박서연은 결과를 문서로 정리했다. '편향 보정 알고리즘 설계 및 검증'. 15페이지. 수식, 그래프, 분석. 시민M과 이준호에게 보냈다.

이틀 후 회의. 이번에는 오프라인. 강남역 코워킹 스페이스.

"서연 님, 문서 받았어요. 대단해요."

이준호가 말했다.

"근데 솔직히 수식이 너무 복잡해서 제가 다 이해는 못했어요."

"괜찮아요. 제가 코드로 구현했으니까 그거 쓰시면 돼요."

"이거 백엔드에 통합하려면 시간이 좀 걸릴 것 같아요. API를 새로 만들어야 하고."

"천천히 하세요. 제가 도와드릴 수 있는 부분 있으면 말씀하세요."

시민M이 물었다.

"서연 님, 이 알고리즘이 적용되면 뭐가 달라지나요? 사용자 입장에서."

"신뢰도 점수가 더 정확해져요. 지금은 진보 성향 사용자가 많으면 진보 언론 점수가 높게 나와요. 하지만 알고리즘 적용 후에는 실제 품질을 반영하는 점수가 나올 거예요."

"그럼 사람들이 더 신뢰할 수 있겠네요."

"그렇죠. 투명하게 공개하면. 어떤 방식으로 보정하는지 설명하고."

회의가 끝나고, 세 사람은 근처 식당에서 저녁을 먹었다. 삼겹살. 소주. 편한 분위기.

"서연 님, 처음엔 회의적이셨잖아요."

시민M이 말했다.

"지금도 회의적이에요."

"그런데 왜 참여하신 거예요?"

박서연은 소주잔을 비웠다.

"재미있어서요. 연구만 하다가 실제 서비스에 적용하는 거. 그리고 의미도 있고. 언론 신뢰 회복. 데이터 과학자로서 기여할 수 있는 일이니까."

"성공할 거라고 생각하세요?"

"확률은 낮아요. 10% 미만. 근데 0%는 아니에요. 그리고 실패해도 배우는 게 있을 거예요."

이준호가 웃었다.

"저도 비슷해요. 성공 확률 낮다고 생각해요. 근데 해볼 만한 가치는 있어요."

시민M이 말했다.

"저는 확신해요. 꼭 성공할 거예요."

"근거가 뭐예요?"

"없어요. 그냥 믿어요."

박서연과 이준호는 서로를 보고 웃었다. 시민M의 순진한 확신. 하지만 나쁘지 않았다. 프로젝트를 이끌어가는 건 결국 이런 확신이니까.

---

## 에필로그

6월. 편향 보정 알고리즘이 CR 플랫폼에 통합됐다. 사용자 수는 200명으로 늘었다. 평가 데이터도 충분히 쌓였다. 알고리즘을 작동시킬 준비가 됐다.

박서연은 백엔드 서버에 접속해서 스크립트를 실행했다.

```python
python bias_correction.py --run
```

콘솔에 로그가 흐르기 시작했다.

```
Analyzing user evaluation patterns...
Calculating bias coefficients...
User 1: bias_coeff = 0.72 (progressive)
User 2: bias_coeff = -0.68 (conservative)
User 3: bias_coeff = 0.03 (neutral)
...
Adjusting trust scores...
조선일보: 5.2 -> 6.9
한겨레: 7.8 -> 7.2
중앙일보: 6.1 -> 6.8
...
Done.
```

박서연은 결과를 확인했다. 보정 전과 후를 비교한 그래프. 점수들이 중앙으로 수렴했다. 극단이 사라졌다. 알고리즘이 작동했다.

시민M에게 메시지를 보냈다.

"알고리즘 적용 완료. 결과 확인해보세요."

시민M이 사이트에 접속했다. 언론사 신뢰도 페이지. 점수가 바뀌어 있었다. 그리고 새로운 섹션이 추가됐다. '신뢰도 계산 방법'.

클릭했다. 설명이 나왔다.

"Citizen Review는 편향 보정 알고리즘을 사용합니다. 각 사용자의 평가 패턴을 분석하여 확증 편향을 측정하고, 평가 가중치를 조정합니다. 이를 통해 정치적 성향과 무관하게 언론의 실제 품질을 반영하는 신뢰도를 계산합니다. 자세한 내용은 [기술 문서]를 참고하세요."

시민M은 전화를 걸었다.

"서연 님, 정말 감사해요. 드디어 제대로 된 신뢰도가 나왔어요."

"잘 작동하나 봐요. 다행이네요."

"이제 사람들한테 자신 있게 설명할 수 있어요. 우리 플랫폼이 왜 다른지."

"과대 광고는 하지 마세요. 아직 완벽하지 않아요."

"알아요. 근데 시작은 했잖아요. 데이터 과학으로."

박서연은 웃었다. 시민M의 말이 맞았다. 시작했다. 확률 10%. 하지만 0%는 아니다. 그리고 시도는 했다. 알고리즘으로. 데이터로.

연구실로 돌아가는 길에 박서연은 생각했다. 이 프로젝트가 성공할까. 모른다. 하지만 의미는 있다. 연구가 논문에만 머물지 않고, 실제 세상에 적용되고 있다. 비록 작은 플랫폼이지만, 200명의 사용자가 쓰고 있고, 그들이 평가한 데이터가 알고리즘을 통해 의미 있는 정보로 변환되고 있다.

데이터 과학자로서 이보다 더 보람 있는 일이 또 있을까.

다음 주에도 작업할 것이다. 알고리즘을 개선하고, 새로운 기능을 추가하고. 확률 10%. 하지만 해볼 만한 가치는 있다.

알고리즘의 공정성. 데이터로 증명한다.

---

**(8,500자)**

**작가노트**

Story 047은 기획자 시민M과 데이터 과학자 박서연의 만남과 협력을 그린다. AI 윤리 세미나라는 채널을 통해 만나고, 편향 보정이라는 기술적 과제를 해결하는 과정을 차분하게 그렸다.

서술:대화 비율 = 8:2
- 서술: 약 6,800자 (80%)
- 대화: 약 1,700자 (20%)

주제: 데이터의 객관성, 편향의 인식과 보정, 연구의 실제 적용
분위기: 차분하고 분석적, 협력의 전문성
